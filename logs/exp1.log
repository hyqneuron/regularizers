Sequential (
  (conv1_1): Sequential (
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (conv1_2): Sequential (
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (pool1): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
  (conv2_1): Sequential (
    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (conv2_2): Sequential (
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (pool2): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
  (conv3_1): Sequential (
    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (conv3_2): Sequential (
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (pool3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
  (conv4_1): Sequential (
    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (conv4_2): Sequential (
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (pool4): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
  (conv5_1): Sequential (
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (conv5_2): Sequential (
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (pool5): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
  (fc6): Sequential (
    (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (logit): Conv2d(256, 10, kernel_size=(1, 1), stride=(1, 1))
  (flatter): Flatten()
)
{'L1_decay': 5e-06,
 'batch_size': 128,
 'force_name': True,
 'graphfolder': 'logs/exp1_graphs/',
 'learning_rate': 0.1,
 'logfile': 'logs/exp1.log',
 'mode': '',
 'name': 'exp1',
 'num_base': 32,
 'optimizer': 'SGD',
 'weight_decay': 0.0005}
Decayed training with schedule: [20, 20, 20, 20, 20]
  0   0  50, 1.836363 [0.393695/72.055633] [   0/1.836363]
  0   0 100, 3.314534 [0.385814/71.921115] [  50/1.836363]
  0   0 150, 4.624877 [0.329119/71.783768] [ 100/1.836363]
  0   0 200, 5.848756 [0.345253/71.645020] [ 150/1.836363]
  0   0 250, 6.992679 [0.346165/71.507022] [ 200/1.836363]
  0   0 300, 8.079140 [0.330310/71.367936] [ 250/1.836363]
  0   0 350, 9.119630 [0.311277/71.224496] [ 300/1.836363]
Epoch 0 done. Evaluation:
(26916, 50000)
(5746, 10000)
  0   1  50, 0.912679 [0.340903/70.970504] [   0/0.912679]
  0   1 100, 1.793723 [0.352374/70.832201] [  50/0.912679]
  0   1 150, 2.665740 [0.310171/70.693548] [ 100/0.912679]
  0   1 200, 3.519946 [0.386144/70.552474] [ 150/0.912679]
  0   1 250, 4.340386 [0.349759/70.412347] [ 200/0.912679]
  0   1 300, 5.155429 [0.314468/70.270268] [ 250/0.912679]
  0   1 350, 5.950259 [0.300236/70.128203] [ 300/0.912679]
Epoch 1 done. Evaluation:
(35079, 50000)
(6966, 10000)
  0   2  50, 0.682253 [0.329506/69.872993] [   0/0.682253]
  0   2 100, 1.364921 [0.320585/69.734362] [  50/0.682253]
  0   2 150, 2.067534 [0.297425/69.594710] [ 100/0.682253]
  0   2 200, 2.736957 [0.310646/69.458264] [ 150/0.682253]
  0   2 250, 3.408741 [0.237324/69.318092] [ 200/0.682253]
  0   2 300, 4.050234 [0.286903/69.179268] [ 250/0.682253]
  0   2 350, 4.691793 [0.312541/69.039389] [ 300/0.682253]
Epoch 2 done. Evaluation:
(38179, 50000)
(7255, 10000)
  0   3  50, 0.563932 [0.281731/68.787250] [   0/0.563932]
  0   3 100, 1.128854 [0.283550/68.652687] [  50/0.563932]
  0   3 150, 1.708229 [0.294154/68.517825] [ 100/0.563932]
  0   3 200, 2.265741 [0.316308/68.382828] [ 150/0.563932]
  0   3 250, 2.833767 [0.332741/68.247655] [ 200/0.563932]
  0   3 300, 3.409654 [0.333850/68.111372] [ 250/0.563932]
  0   3 350, 3.974192 [0.270336/67.977503] [ 300/0.563932]
Epoch 3 done. Evaluation:
(40036, 50000)
(6838, 10000)
  0   4  50, 0.487606 [0.290300/67.735891] [   0/0.487606]
  0   4 100, 0.972053 [0.363406/67.605338] [  50/0.487606]
  0   4 150, 1.467198 [0.330996/67.474761] [ 100/0.487606]
  0   4 200, 1.950388 [0.344902/67.343440] [ 150/0.487606]
  0   4 250, 2.450958 [0.313879/67.215734] [ 200/0.487606]
  0   4 300, 2.956622 [0.337212/67.083086] [ 250/0.487606]
  0   4 350, 3.442448 [0.332721/66.952370] [ 300/0.487606]
Epoch 4 done. Evaluation:
(41407, 50000)
(7565, 10000)
  0   5  50, 0.402630 [0.312517/66.715340] [   0/0.402630]
  0   5 100, 0.832268 [0.260970/66.586498] [  50/0.402630]
  0   5 150, 1.254266 [0.297034/66.461521] [ 100/0.402630]
  0   5 200, 1.702822 [0.308099/66.333047] [ 150/0.402630]
  0   5 250, 2.142314 [0.270471/66.207807] [ 200/0.402630]
  0   5 300, 2.574770 [0.317247/66.083043] [ 250/0.402630]
  0   5 350, 3.039980 [0.321187/65.955865] [ 300/0.402630]
Epoch 5 done. Evaluation:
(42556, 50000)
(7818, 10000)
  0   6  50, 0.376796 [0.338861/65.728144] [   0/0.376796]
  0   6 100, 0.749136 [0.352730/65.607508] [  50/0.376796]
  0   6 150, 1.133493 [0.285897/65.487155] [ 100/0.376796]
  0   6 200, 1.518598 [0.352083/65.364723] [ 150/0.376796]
  0   6 250, 1.908853 [0.260257/65.244290] [ 200/0.376796]
  0   6 300, 2.304733 [0.265005/65.123119] [ 250/0.376796]
  0   6 350, 2.711673 [0.241470/65.001959] [ 300/0.376796]
Epoch 6 done. Evaluation:
(43228, 50000)
(7802, 10000)
  0   7  50, 0.316741 [0.278869/64.782515] [   0/0.316741]
  0   7 100, 0.647038 [0.321332/64.665351] [  50/0.316741]
  0   7 150, 0.976389 [0.244541/64.547312] [ 100/0.316741]
  0   7 200, 1.329181 [0.323380/64.428354] [ 150/0.316741]
  0   7 250, 1.674319 [0.267290/64.311974] [ 200/0.316741]
  0   7 300, 2.017494 [0.298800/64.193491] [ 250/0.316741]
  0   7 350, 2.372961 [0.349140/64.076553] [ 300/0.316741]
Epoch 7 done. Evaluation:
(44116, 50000)
(7926, 10000)
  0   8  50, 0.280284 [0.351614/63.866194] [   0/0.280284]
  0   8 100, 0.577266 [0.237558/63.750154] [  50/0.280284]
  0   8 150, 0.886392 [0.333953/63.637435] [ 100/0.280284]
  0   8 200, 1.192352 [0.330557/63.524210] [ 150/0.280284]
  0   8 250, 1.508504 [0.348090/63.410168] [ 200/0.280284]
  0   8 300, 1.812411 [0.380823/63.296054] [ 250/0.280284]
  0   8 350, 2.148897 [0.321685/63.181050] [ 300/0.280284]
Epoch 8 done. Evaluation:
(44640, 50000)
(7589, 10000)
  0   9  50, 0.243389 [0.342669/62.975609] [   0/0.243389]
  0   9 100, 0.483763 [0.397631/62.864792] [  50/0.243389]
  0   9 150, 0.755487 [0.332636/62.752382] [ 100/0.243389]
  0   9 200, 1.027188 [0.331683/62.642464] [ 150/0.243389]
  0   9 250, 1.308180 [0.283614/62.531214] [ 200/0.243389]
  0   9 300, 1.604045 [0.280981/62.421716] [ 250/0.243389]
  0   9 350, 1.897977 [0.311454/62.311364] [ 300/0.243389]
Epoch 9 done. Evaluation:
(45266, 50000)
(7952, 10000)
  0  10  50, 0.214015 [0.267577/62.110787] [   0/0.214015]
  0  10 100, 0.444841 [0.334821/62.001667] [  50/0.214015]
  0  10 150, 0.691748 [0.369583/61.894733] [ 100/0.214015]
  0  10 200, 0.946597 [0.337506/61.786867] [ 150/0.214015]
  0  10 250, 1.185689 [0.304240/61.681264] [ 200/0.214015]
  0  10 300, 1.446487 [0.315405/61.576779] [ 250/0.214015]
  0  10 350, 1.704631 [0.279748/61.471416] [ 300/0.214015]
Epoch 10 done. Evaluation:
(45785, 50000)
(7992, 10000)
  0  11  50, 0.199964 [0.332319/61.275908] [   0/0.199964]
  0  11 100, 0.401658 [0.329025/61.167783] [  50/0.199964]
  0  11 150, 0.624103 [0.305594/61.064238] [ 100/0.199964]
  0  11 200, 0.851172 [0.287363/60.963493] [ 150/0.199964]
  0  11 250, 1.083549 [0.268636/60.861391] [ 200/0.199964]
  0  11 300, 1.334912 [0.323168/60.760447] [ 250/0.199964]
  0  11 350, 1.595819 [0.368243/60.661546] [ 300/0.199964]
Epoch 11 done. Evaluation:
(45975, 50000)
(7859, 10000)
  0  12  50, 0.181036 [0.232487/60.468307] [   0/0.181036]
  0  12 100, 0.363041 [0.391114/60.362831] [  50/0.181036]
  0  12 150, 0.537267 [0.312901/60.256728] [ 100/0.181036]
  0  12 200, 0.751716 [0.299616/60.156606] [ 150/0.181036]
  0  12 250, 0.961612 [0.315798/60.058216] [ 200/0.181036]
  0  12 300, 1.182423 [0.323205/59.960464] [ 250/0.181036]
  0  12 350, 1.405430 [0.285168/59.861101] [ 300/0.181036]
Epoch 12 done. Evaluation:
(46501, 50000)
(7866, 10000)
  0  13  50, 0.172134 [0.249073/59.675073] [   0/0.172134]
  0  13 100, 0.335611 [0.305838/59.572112] [  50/0.172134]
  0  13 150, 0.517194 [0.382902/59.471332] [ 100/0.172134]
  0  13 200, 0.698038 [0.322234/59.369144] [ 150/0.172134]
  0  13 250, 0.903200 [0.312245/59.273226] [ 200/0.172134]
  0  13 300, 1.105520 [0.381102/59.177089] [ 250/0.172134]
  0  13 350, 1.304362 [0.267676/59.082148] [ 300/0.172134]
Epoch 13 done. Evaluation:
(46723, 50000)
(7873, 10000)
  0  14  50, 0.145855 [0.309487/58.895790] [   0/0.145855]
  0  14 100, 0.301579 [0.397290/58.796414] [  50/0.145855]
  0  14 150, 0.463997 [0.335069/58.697038] [ 100/0.145855]
  0  14 200, 0.636336 [0.325611/58.601561] [ 150/0.145855]
  0  14 250, 0.801376 [0.318457/58.504087] [ 200/0.145855]
  0  14 300, 0.976991 [0.303260/58.407607] [ 250/0.145855]
  0  14 350, 1.159502 [0.363724/58.309980] [ 300/0.145855]
Epoch 14 done. Evaluation:
(47120, 50000)
(7904, 10000)
  0  15  50, 0.124433 [0.297953/58.126344] [   0/0.124433]
  0  15 100, 0.258077 [0.217671/58.027288] [  50/0.124433]
  0  15 150, 0.407610 [0.348864/57.929803] [ 100/0.124433]
  0  15 200, 0.562596 [0.282618/57.832809] [ 150/0.124433]
  0  15 250, 0.717314 [0.363486/57.739976] [ 200/0.124433]
  0  15 300, 0.870812 [0.339930/57.646346] [ 250/0.124433]
  0  15 350, 1.056877 [0.352242/57.561673] [ 300/0.124433]
Epoch 15 done. Evaluation:
(47378, 50000)
(7705, 10000)
  0  16  50, 0.113780 [0.405364/57.382396] [   0/0.113780]
  0  16 100, 0.232890 [0.261739/57.281969] [  50/0.113780]
  0  16 150, 0.372656 [0.269738/57.188666] [ 100/0.113780]
  0  16 200, 0.506695 [0.331319/57.092235] [ 150/0.113780]
  0  16 250, 0.650871 [0.294054/57.003097] [ 200/0.113780]
  0  16 300, 0.800757 [0.435908/56.912917] [ 250/0.113780]
  0  16 350, 0.946444 [0.234490/56.821718] [ 300/0.113780]
Epoch 16 done. Evaluation:
(47636, 50000)
(7938, 10000)
  0  17  50, 0.119886 [0.243232/56.647052] [ 391/0.113780]
  0  17 100, 0.238420 [0.431555/56.549494] [ 441/0.113780]
  0  17 150, 0.357780 [0.336540/56.456273] [ 491/0.113780]
  0  17 200, 0.481578 [0.362051/56.365431] [ 541/0.113780]
  0  17 250, 0.626930 [0.381846/56.277238] [ 591/0.113780]
  0  17 300, 0.765985 [0.261610/56.184205] [ 641/0.113780]
  0  17 350, 0.917672 [0.370976/56.094571] [ 691/0.113780]
Epoch 17 done. Evaluation:
(47683, 50000)
(7929, 10000)
  0  18  50, 0.112679 [0.336829/55.928299] [   0/0.112679]
  0  18 100, 0.230675 [0.303039/55.835281] [  50/0.112679]
  0  18 150, 0.340545 [0.151822/55.741070] [ 100/0.112679]
  0  18 200, 0.468364 [0.377869/55.652079] [ 150/0.112679]
  0  18 250, 0.595236 [0.345708/55.562063] [ 200/0.112679]
  0  18 300, 0.744089 [0.275765/55.478086] [ 250/0.112679]
  0  18 350, 0.883850 [0.365718/55.390456] [ 300/0.112679]
Epoch 18 done. Evaluation:
(47755, 50000)
(7793, 10000)
  0  19  50, 0.093252 [0.208443/55.221439] [   0/0.093252]
  0  19 100, 0.189858 [0.254929/55.123240] [  50/0.093252]
  0  19 150, 0.302300 [0.409013/55.031767] [ 100/0.093252]
  0  19 200, 0.409044 [0.343846/54.939167] [ 150/0.093252]
  0  19 250, 0.542995 [0.286627/54.853030] [ 200/0.093252]
  0  19 300, 0.668409 [0.322048/54.766546] [ 250/0.093252]
  0  19 350, 0.804976 [0.246514/54.682305] [ 300/0.093252]
Epoch 19 done. Evaluation:
(47951, 50000)
(7762, 10000)
  1   0  50, 0.084729 [0.166941/54.560185] [   0/0.084729]
  1   0 100, 0.149626 [0.152453/54.501351] [  50/0.084729]
  1   0 150, 0.205722 [0.092818/54.442068] [ 100/0.084729]
  1   0 200, 0.261302 [0.152888/54.382529] [ 150/0.084729]
  1   0 250, 0.308064 [0.071398/54.322969] [ 200/0.084729]
  1   0 300, 0.348177 [0.118260/54.262616] [ 250/0.084729]
  1   0 350, 0.391394 [0.080679/54.202533] [ 300/0.084729]
Epoch 0 done. Evaluation:
(49191, 50000)
(8463, 10000)
  1   1  50, 0.027727 [0.084897/54.091613] [   0/0.027727]
  1   1 100, 0.056256 [0.102540/54.029463] [  50/0.027727]
  1   1 150, 0.080380 [0.049048/53.967506] [ 100/0.027727]
  1   1 200, 0.105878 [0.085855/53.905427] [ 150/0.027727]
  1   1 250, 0.138424 [0.026477/53.844864] [ 200/0.027727]
  1   1 300, 0.165304 [0.035108/53.783550] [ 250/0.027727]
  1   1 350, 0.192269 [0.022776/53.722573] [ 300/0.027727]
Epoch 1 done. Evaluation:
(49657, 50000)
(8429, 10000)
  1   2  50, 0.016369 [0.024876/53.609537] [   0/0.016369]
  1   2 100, 0.033737 [0.107155/53.546928] [  50/0.016369]
  1   2 150, 0.049208 [0.057234/53.484367] [ 100/0.016369]
  1   2 200, 0.065864 [0.043389/53.421804] [ 150/0.016369]
  1   2 250, 0.083881 [0.031193/53.359254] [ 200/0.016369]
  1   2 300, 0.100487 [0.064602/53.296913] [ 250/0.016369]
  1   2 350, 0.117724 [0.035804/53.235106] [ 300/0.016369]
Epoch 2 done. Evaluation:
(49835, 50000)
(8456, 10000)
  1   3  50, 0.012493 [0.031246/53.121211] [   0/0.012493]
  1   3 100, 0.026416 [0.104531/53.058561] [  50/0.012493]
  1   3 150, 0.037045 [0.023369/52.995592] [ 100/0.012493]
  1   3 200, 0.046883 [0.068945/52.932667] [ 150/0.012493]
  1   3 250, 0.057661 [0.044027/52.869613] [ 200/0.012493]
  1   3 300, 0.069898 [0.090130/52.807127] [ 250/0.012493]
  1   3 350, 0.081580 [0.021718/52.744614] [ 300/0.012493]
Epoch 3 done. Evaluation:
(49902, 50000)
(8453, 10000)
  1   4  50, 0.009108 [0.054369/52.630859] [   0/0.009108]
  1   4 100, 0.017627 [0.044559/52.567909] [  50/0.009108]
  1   4 150, 0.025548 [0.048036/52.504920] [ 100/0.009108]
  1   4 200, 0.034205 [0.047543/52.442197] [ 150/0.009108]
  1   4 250, 0.043504 [0.008228/52.379579] [ 200/0.009108]
  1   4 300, 0.052584 [0.100957/52.317168] [ 250/0.009108]
  1   4 350, 0.061959 [0.015174/52.254846] [ 300/0.009108]
Epoch 4 done. Evaluation:
(49938, 50000)
(8485, 10000)
  1   5  50, 0.006524 [0.011219/52.140770] [   0/0.006524]
  1   5 100, 0.011868 [0.026451/52.077768] [  50/0.006524]
  1   5 150, 0.018025 [0.014797/52.015031] [ 100/0.006524]
  1   5 200, 0.023764 [0.007099/51.952280] [ 150/0.006524]
  1   5 250, 0.029267 [0.041444/51.889498] [ 200/0.006524]
  1   5 300, 0.037625 [0.020624/51.827370] [ 250/0.006524]
  1   5 350, 0.047197 [0.052974/51.765475] [ 300/0.006524]
Epoch 5 done. Evaluation:
(49960, 50000)
(8498, 10000)
  1   6  50, 0.005363 [0.006663/51.651601] [   0/0.005363]
  1   6 100, 0.009669 [0.007514/51.588918] [  50/0.005363]
  1   6 150, 0.014531 [0.004903/51.526470] [ 100/0.005363]
  1   6 200, 0.019144 [0.016710/51.463917] [ 150/0.005363]
  1   6 250, 0.025120 [0.022311/51.401549] [ 200/0.005363]
  1   6 300, 0.028999 [0.021160/51.339026] [ 250/0.005363]
  1   6 350, 0.033949 [0.017395/51.276926] [ 300/0.005363]
Epoch 6 done. Evaluation:
(49979, 50000)
(8485, 10000)
  1   7  50, 0.003622 [0.012944/51.163527] [   0/0.003622]
  1   7 100, 0.007119 [0.032762/51.101236] [  50/0.003622]
  1   7 150, 0.010254 [0.004781/51.038868] [ 100/0.003622]
  1   7 200, 0.013779 [0.025106/50.976707] [ 150/0.003622]
  1   7 250, 0.017278 [0.052029/50.914602] [ 200/0.003622]
  1   7 300, 0.021147 [0.007629/50.852706] [ 250/0.003622]
  1   7 350, 0.024746 [0.016878/50.790773] [ 300/0.003622]
Epoch 7 done. Evaluation:
(49997, 50000)
(8516, 10000)
  1   8  50, 0.004193 [0.023096/50.678444] [ 391/0.003622]
  1   8 100, 0.007770 [0.016799/50.616711] [ 441/0.003622]
  1   8 150, 0.011150 [0.003310/50.555046] [ 491/0.003622]
  1   8 200, 0.014369 [0.004857/50.493363] [ 541/0.003622]
  1   8 250, 0.017317 [0.008800/50.431698] [ 591/0.003622]
  1   8 300, 0.021011 [0.003424/50.370312] [ 641/0.003622]
  1   8 350, 0.023882 [0.012152/50.308770] [ 691/0.003622]
Epoch 8 done. Evaluation:
(49992, 50000)
(8483, 10000)
  1   9  50, 0.003035 [0.015173/50.197344] [   0/0.003035]
  1   9 100, 0.005287 [0.006189/50.135823] [  50/0.003035]
  1   9 150, 0.007811 [0.004236/50.074462] [ 100/0.003035]
  1   9 200, 0.010447 [0.012670/50.013239] [ 150/0.003035]
  1   9 250, 0.013431 [0.008449/49.952255] [ 200/0.003035]
  1   9 300, 0.016218 [0.002733/49.891205] [ 250/0.003035]
  1   9 350, 0.018992 [0.028455/49.830241] [ 300/0.003035]
Epoch 9 done. Evaluation:
(49995, 50000)
(8371, 10000)
  1  10  50, 0.002759 [0.007039/49.719802] [   0/0.002759]
  1  10 100, 0.005411 [0.016979/49.659034] [  50/0.002759]
  1  10 150, 0.007820 [0.004611/49.598271] [ 100/0.002759]
  1  10 200, 0.010285 [0.005482/49.537586] [ 150/0.002759]
  1  10 250, 0.012690 [0.006583/49.476960] [ 200/0.002759]
  1  10 300, 0.015388 [0.006216/49.416501] [ 250/0.002759]
  1  10 350, 0.017596 [0.006349/49.355963] [ 300/0.002759]
Epoch 10 done. Evaluation:
(49998, 50000)
(8516, 10000)
  1  11  50, 0.002180 [0.012357/49.246017] [   0/0.002180]
  1  11 100, 0.004540 [0.006456/49.185773] [  50/0.002180]
  1  11 150, 0.006868 [0.005457/49.125553] [ 100/0.002180]
  1  11 200, 0.008883 [0.004985/49.065302] [ 150/0.002180]
  1  11 250, 0.011203 [0.008421/49.005237] [ 200/0.002180]
  1  11 300, 0.013419 [0.003529/48.945220] [ 250/0.002180]
  1  11 350, 0.015635 [0.007006/48.885281] [ 300/0.002180]
Epoch 11 done. Evaluation:
(49999, 50000)
(8529, 10000)
  1  12  50, 0.001792 [0.004199/48.776333] [   0/0.001792]
  1  12 100, 0.004076 [0.009006/48.716625] [  50/0.001792]
  1  12 150, 0.006078 [0.006070/48.656899] [ 100/0.001792]
  1  12 200, 0.008078 [0.010227/48.597255] [ 150/0.001792]
  1  12 250, 0.010003 [0.007128/48.537656] [ 200/0.001792]
  1  12 300, 0.012174 [0.008079/48.478223] [ 250/0.001792]
  1  12 350, 0.014064 [0.016003/48.418760] [ 300/0.001792]
Epoch 12 done. Evaluation:
(50000, 50000)
(8515, 10000)
  1  13  50, 0.001915 [0.004413/48.310813] [ 391/0.001792]
  1  13 100, 0.003851 [0.007387/48.251590] [ 441/0.001792]
  1  13 150, 0.005598 [0.007063/48.192355] [ 491/0.001792]
  1  13 200, 0.007265 [0.010598/48.133166] [ 541/0.001792]
  1  13 250, 0.009045 [0.011165/48.074104] [ 591/0.001792]
  1  13 300, 0.010898 [0.003285/48.015136] [ 641/0.001792]
  1  13 350, 0.012860 [0.003863/47.956266] [ 691/0.001792]
Epoch 13 done. Evaluation:
(49999, 50000)
(8529, 10000)
  1  14  50, 0.001906 [0.016647/47.849399] [ 782/0.001792]
  1  14 100, 0.003635 [0.005314/47.790666] [ 832/0.001792]
  1  14 150, 0.005576 [0.003510/47.732106] [ 882/0.001792]
  1  14 200, 0.007369 [0.004939/47.673562] [ 932/0.001792]
  1  14 250, 0.009278 [0.004600/47.615140] [ 982/0.001792]
  1  14 300, 0.011196 [0.002422/47.556799] [1032/0.001792]
  1  14 350, 0.013204 [0.013999/47.498547] [1082/0.001792]
Epoch 14 done. Evaluation:
(50000, 50000)
(8530, 10000)
  1  15  50, 0.001853 [0.002858/47.392719] [1173/0.001792]
  1  15 100, 0.003513 [0.009540/47.334545] [1223/0.001792]
  1  15 150, 0.005401 [0.008382/47.276555] [1273/0.001792]
  1  15 200, 0.007260 [0.004404/47.218626] [1323/0.001792]
  1  15 250, 0.009025 [0.006788/47.160733] [1373/0.001792]
  1  15 300, 0.010806 [0.006680/47.102917] [1423/0.001792]
  1  15 350, 0.012744 [0.007138/47.045234] [1473/0.001792]
Epoch 15 done. Evaluation:
(49999, 50000)
(8529, 10000)
  1  16  50, 0.001905 [0.004406/46.940433] [1564/0.001792]
  1  16 100, 0.003612 [0.012001/46.882858] [1614/0.001792]
  1  16 150, 0.005265 [0.002996/46.825351] [1664/0.001792]
  1  16 200, 0.006929 [0.004283/46.767916] [1714/0.001792]
  1  16 250, 0.008767 [0.012437/46.710630] [1764/0.001792]
  1  16 300, 0.010624 [0.005462/46.653417] [1814/0.001792]
  1  16 350, 0.012570 [0.014144/46.596340] [1864/0.001792]
Epoch 16 done. Evaluation:
(50000, 50000)
(8520, 10000)
  1  17  50, 0.001641 [0.002192/46.492481] [   0/0.001641]
  1  17 100, 0.003435 [0.005412/46.435540] [  50/0.001641]
  1  17 150, 0.005094 [0.006000/46.378612] [ 100/0.001641]
  1  17 200, 0.006864 [0.006293/46.321802] [ 150/0.001641]
  1  17 250, 0.008401 [0.003572/46.264963] [ 200/0.001641]
  1  17 300, 0.010109 [0.004975/46.208278] [ 250/0.001641]
  1  17 350, 0.011856 [0.005346/46.151680] [ 300/0.001641]
Epoch 17 done. Evaluation:
(50000, 50000)
(8539, 10000)
  1  18  50, 0.001651 [0.003461/46.048912] [ 391/0.001641]
  1  18 100, 0.003196 [0.003425/45.992426] [ 441/0.001641]
  1  18 150, 0.005149 [0.004115/45.936187] [ 491/0.001641]
  1  18 200, 0.006888 [0.004625/45.879936] [ 541/0.001641]
  1  18 250, 0.008556 [0.004721/45.823724] [ 591/0.001641]
  1  18 300, 0.010310 [0.002474/45.767624] [ 641/0.001641]
  1  18 350, 0.011987 [0.004672/45.711563] [ 691/0.001641]
Epoch 18 done. Evaluation:
(50000, 50000)
(8518, 10000)
  1  19  50, 0.001837 [0.006160/45.609811] [ 782/0.001641]
  1  19 100, 0.003476 [0.003619/45.553932] [ 832/0.001641]
  1  19 150, 0.005209 [0.002182/45.498164] [ 882/0.001641]
  1  19 200, 0.006884 [0.003467/45.442439] [ 932/0.001641]
  1  19 250, 0.008581 [0.007619/45.386801] [ 982/0.001641]
  1  19 300, 0.010335 [0.007082/45.331279] [1032/0.001641]
  1  19 350, 0.012079 [0.003496/45.275814] [1082/0.001641]
Epoch 19 done. Evaluation:
(50000, 50000)
(8522, 10000)
  2   0  50, 0.001631 [0.003734/45.202664] [   0/0.001631]
  2   0 100, 0.003237 [0.002521/45.174965] [  50/0.001631]
  2   0 150, 0.004737 [0.003253/45.147261] [ 100/0.001631]
  2   0 200, 0.006317 [0.001164/45.119590] [ 150/0.001631]
  2   0 250, 0.008044 [0.004013/45.091969] [ 200/0.001631]
  2   0 300, 0.009726 [0.002532/45.064359] [ 250/0.001631]
  2   0 350, 0.011604 [0.002100/45.036804] [ 300/0.001631]
Epoch 0 done. Evaluation:
(50000, 50000)
(8515, 10000)
  2   1  50, 0.001545 [0.001828/44.986572] [   0/0.001545]
  2   1 100, 0.003240 [0.006478/44.959035] [  50/0.001545]
  2   1 150, 0.004718 [0.001448/44.931465] [ 100/0.001545]
  2   1 200, 0.006429 [0.002323/44.903967] [ 150/0.001545]
  2   1 250, 0.008087 [0.001456/44.876480] [ 200/0.001545]
  2   1 300, 0.009772 [0.002228/44.849009] [ 250/0.001545]
  2   1 350, 0.011441 [0.001427/44.821552] [ 300/0.001545]
Epoch 1 done. Evaluation:
(50000, 50000)
(8521, 10000)
  2   2  50, 0.001603 [0.001118/44.771632] [ 391/0.001545]
  2   2 100, 0.003233 [0.002979/44.744219] [ 441/0.001545]
  2   2 150, 0.004833 [0.003911/44.716819] [ 491/0.001545]
  2   2 200, 0.006499 [0.004123/44.689443] [ 541/0.001545]
  2   2 250, 0.008106 [0.001524/44.662076] [ 591/0.001545]
  2   2 300, 0.009771 [0.001427/44.634737] [ 641/0.001545]
  2   2 350, 0.011549 [0.006276/44.607449] [ 691/0.001545]
Epoch 2 done. Evaluation:
(50000, 50000)
(8517, 10000)
  2   3  50, 0.001636 [0.001313/44.557818] [ 782/0.001545]
  2   3 100, 0.003104 [0.002481/44.530505] [ 832/0.001545]
  2   3 150, 0.004744 [0.002392/44.503255] [ 882/0.001545]
  2   3 200, 0.006238 [0.003552/44.475984] [ 932/0.001545]
  2   3 250, 0.007982 [0.002477/44.448784] [ 982/0.001545]
  2   3 300, 0.009626 [0.001856/44.421572] [1032/0.001545]
  2   3 350, 0.011254 [0.001635/44.394384] [1082/0.001545]
Epoch 3 done. Evaluation:
(50000, 50000)
(8518, 10000)
  2   4  50, 0.001685 [0.004000/44.345033] [1173/0.001545]
  2   4 100, 0.003341 [0.004505/44.317896] [1223/0.001545]
  2   4 150, 0.005061 [0.001379/44.290802] [1273/0.001545]
  2   4 200, 0.006628 [0.001527/44.263690] [1323/0.001545]
  2   4 250, 0.008204 [0.001624/44.236597] [1373/0.001545]
  2   4 300, 0.009926 [0.003069/44.209550] [1423/0.001545]
  2   4 350, 0.011370 [0.001655/44.182459] [1473/0.001545]
Epoch 4 done. Evaluation:
(50000, 50000)
(8515, 10000)
  2   5  50, 0.001627 [0.003888/44.133301] [1564/0.001545]
  2   5 100, 0.003469 [0.002047/44.106348] [1614/0.001545]
  2   5 150, 0.005141 [0.005063/44.079373] [1664/0.001545]
  2   5 200, 0.006742 [0.002080/44.052403] [1714/0.001545]
  2   5 250, 0.008351 [0.002818/44.025456] [1764/0.001545]
  2   5 300, 0.009979 [0.001417/43.998527] [1814/0.001545]
  2   5 350, 0.011542 [0.002918/43.971598] [1864/0.001545]
Epoch 5 done. Evaluation:
(50000, 50000)
(8516, 10000)
  2   6  50, 0.001668 [0.003159/43.922689] [1955/0.001545]
  2   6 100, 0.003316 [0.002667/43.895832] [2005/0.001545]
  2   6 150, 0.004981 [0.001321/43.868997] [2055/0.001545]
  2   6 200, 0.006664 [0.007104/43.842181] [2105/0.001545]
  2   6 250, 0.008161 [0.001627/43.815341] [2155/0.001545]
  2   6 300, 0.009670 [0.002477/43.788518] [2205/0.001545]
  2   6 350, 0.011254 [0.001605/43.761732] [2255/0.001545]
Epoch 6 done. Evaluation:
(50000, 50000)
(8502, 10000)
  2   7  50, 0.001509 [0.002384/43.712962] [   0/0.001509]
  2   7 100, 0.003015 [0.001293/43.686210] [  50/0.001509]
  2   7 150, 0.004441 [0.001791/43.659455] [ 100/0.001509]
  2   7 200, 0.005998 [0.001665/43.632744] [ 150/0.001509]
  2   7 250, 0.007600 [0.001620/43.606066] [ 200/0.001509]
  2   7 300, 0.009271 [0.001871/43.579420] [ 250/0.001509]
  2   7 350, 0.010905 [0.001582/43.552773] [ 300/0.001509]
Epoch 7 done. Evaluation:
(50000, 50000)
(8534, 10000)
  2   8  50, 0.001545 [0.004225/43.504308] [ 391/0.001509]
  2   8 100, 0.003202 [0.001101/43.477722] [ 441/0.001509]
  2   8 150, 0.004836 [0.003744/43.451148] [ 491/0.001509]
  2   8 200, 0.006412 [0.001218/43.424580] [ 541/0.001509]
  2   8 250, 0.008091 [0.001055/43.398053] [ 591/0.001509]
  2   8 300, 0.009761 [0.002578/43.371534] [ 641/0.001509]
  2   8 350, 0.011254 [0.001806/43.345000] [ 691/0.001509]
Epoch 8 done. Evaluation:
(50000, 50000)
(8536, 10000)
  2   9  50, 0.001567 [0.002910/43.296782] [ 782/0.001509]
  2   9 100, 0.003231 [0.001352/43.270330] [ 832/0.001509]
  2   9 150, 0.004953 [0.001426/43.243903] [ 882/0.001509]
  2   9 200, 0.006625 [0.001836/43.217481] [ 932/0.001509]
  2   9 250, 0.008180 [0.002920/43.191057] [ 982/0.001509]
  2   9 300, 0.009907 [0.002856/43.164693] [1032/0.001509]
  2   9 350, 0.011498 [0.001718/43.138316] [1082/0.001509]
Epoch 9 done. Evaluation:
(50000, 50000)
(8525, 10000)
  2  10  50, 0.001525 [0.001781/43.090332] [1173/0.001509]
  2  10 100, 0.003149 [0.001417/43.064011] [1223/0.001509]
  2  10 150, 0.004738 [0.007315/43.037696] [1273/0.001509]
  2  10 200, 0.006383 [0.001530/43.011409] [1323/0.001509]
  2  10 250, 0.008035 [0.001232/42.985153] [1373/0.001509]
  2  10 300, 0.009533 [0.002082/42.958868] [1423/0.001509]
  2  10 350, 0.011174 [0.001562/42.932629] [1473/0.001509]
Epoch 10 done. Evaluation:
(50000, 50000)
(8547, 10000)
  2  11  50, 0.001691 [0.002067/42.884957] [1564/0.001509]
  2  11 100, 0.003288 [0.002412/42.858755] [1614/0.001509]
  2  11 150, 0.005033 [0.001193/42.832614] [1664/0.001509]
  2  11 200, 0.006652 [0.001953/42.806459] [1714/0.001509]
  2  11 250, 0.008193 [0.002970/42.780294] [1764/0.001509]
  2  11 300, 0.009734 [0.001566/42.754147] [1814/0.001509]
  2  11 350, 0.011382 [0.001074/42.728052] [1864/0.001509]
Epoch 11 done. Evaluation:
(50000, 50000)
(8525, 10000)
  2  12  50, 0.001632 [0.002326/42.680611] [1955/0.001509]
  2  12 100, 0.003223 [0.003041/42.654544] [2005/0.001509]
  2  12 150, 0.004914 [0.001541/42.628515] [2055/0.001509]
  2  12 200, 0.006565 [0.001663/42.602491] [2105/0.001509]
  2  12 250, 0.008117 [0.002115/42.576464] [2155/0.001509]
  2  12 300, 0.009676 [0.001797/42.550458] [2205/0.001509]
  2  12 350, 0.011181 [0.003493/42.524451] [2255/0.001509]
Epoch 12 done. Evaluation:
(50000, 50000)
(8530, 10000)
  2  13  50, 0.001549 [0.001402/42.477213] [2346/0.001509]
  2  13 100, 0.003133 [0.003180/42.451277] [2396/0.001509]
  2  13 150, 0.004727 [0.002567/42.425364] [2446/0.001509]
  2  13 200, 0.006311 [0.001871/42.399464] [2496/0.001509]
  2  13 250, 0.008031 [0.002207/42.373608] [2546/0.001509]
  2  13 300, 0.009502 [0.005005/42.347707] [2596/0.001509]
  2  13 350, 0.011122 [0.006865/42.321868] [2646/0.001509]
Epoch 13 done. Evaluation:
(50000, 50000)
(8535, 10000)
  2  14  50, 0.001562 [0.002670/42.274845] [2737/0.001509]
  2  14 100, 0.003081 [0.004109/42.249022] [2787/0.001509]
  2  14 150, 0.004656 [0.004602/42.223236] [2837/0.001509]
  2  14 200, 0.006279 [0.002230/42.197478] [2887/0.001509]
  2  14 250, 0.007975 [0.004391/42.171761] [2937/0.001509]
  2  14 300, 0.009830 [0.001772/42.146095] [2987/0.001509]
  2  14 350, 0.011505 [0.001380/42.120400] [3037/0.001509]
Epoch 14 done. Evaluation:
(50000, 50000)
(8525, 10000)
  2  15  50, 0.001556 [0.002136/42.073658] [3128/0.001509]
  2  15 100, 0.003203 [0.001283/42.048002] [3178/0.001509]
  2  15 150, 0.005051 [0.002772/42.022410] [3228/0.001509]
  2  15 200, 0.006619 [0.001425/41.996770] [3278/0.001509]
  2  15 250, 0.008319 [0.002083/41.971179] [3328/0.001509]
  2  15 300, 0.009968 [0.001830/41.945587] [3378/0.001509]
  2  15 350, 0.011630 [0.004536/41.920022] [3428/0.001509]
Epoch 15 done. Evaluation:
(50000, 50000)
(8534, 10000)
  2  16  50, 0.001648 [0.001647/41.873517] [3519/0.001509]
  2  16 100, 0.003467 [0.002304/41.848043] [3569/0.001509]
  2  16 150, 0.005105 [0.001819/41.822534] [3619/0.001509]
  2  16 200, 0.006773 [0.001492/41.797049] [3669/0.001509]
  2  16 250, 0.008418 [0.004345/41.771566] [3719/0.001509]
  2  16 300, 0.009948 [0.002045/41.746078] [3769/0.001509]
  2  16 350, 0.011459 [0.002894/41.720600] [3819/0.001509]
Epoch 16 done. Evaluation:
(50000, 50000)
(8515, 10000)
  2  17  50, 0.001701 [0.003455/41.674348] [3910/0.001509]
  2  17 100, 0.003433 [0.004660/41.648972] [3960/0.001509]
  2  17 150, 0.005162 [0.002964/41.623622] [4010/0.001509]
  2  17 200, 0.006730 [0.001483/41.598239] [4060/0.001509]
  2  17 250, 0.008363 [0.001725/41.572894] [4110/0.001509]
  2  17 300, 0.009909 [0.001669/41.547538] [4160/0.001509]
  2  17 350, 0.011388 [0.001568/41.522180] [4210/0.001509]
Epoch 17 done. Evaluation:
(50000, 50000)
(8522, 10000)
  2  18  50, 0.001536 [0.001433/41.476126] [4301/0.001509]
  2  18 100, 0.003060 [0.001088/41.450828] [4351/0.001509]
  2  18 150, 0.004607 [0.001517/41.425550] [4401/0.001509]
  2  18 200, 0.006127 [0.001367/41.400287] [4451/0.001509]
  2  18 250, 0.007791 [0.001879/41.375070] [4501/0.001509]
  2  18 300, 0.009537 [0.001275/41.349901] [4551/0.001509]
  2  18 350, 0.011213 [0.003302/41.324725] [4601/0.001509]
Epoch 18 done. Evaluation:
(50000, 50000)
(8537, 10000)
  2  19  50, 0.001549 [0.002740/41.278910] [4692/0.001509]
  2  19 100, 0.003158 [0.001610/41.253758] [4742/0.001509]
  2  19 150, 0.004777 [0.002396/41.228629] [4792/0.001509]
  2  19 200, 0.006377 [0.001139/41.203514] [4842/0.001509]
  2  19 250, 0.008069 [0.001526/41.178441] [4892/0.001509]
  2  19 300, 0.009848 [0.001659/41.153408] [4942/0.001509]
  2  19 350, 0.011658 [0.001636/41.128376] [4992/0.001509]
Epoch 19 done. Evaluation:
(50000, 50000)
(8530, 10000)
  3   0  50, 0.001504 [0.000565/41.095335] [   0/0.001504]
  3   0 100, 0.003144 [0.002117/41.082820] [  50/0.001504]
  3   0 150, 0.004726 [0.000906/41.070304] [ 100/0.001504]
  3   0 200, 0.006255 [0.001402/41.057782] [ 150/0.001504]
  3   0 250, 0.008018 [0.001283/41.045297] [ 200/0.001504]
  3   0 300, 0.009693 [0.000765/41.032805] [ 250/0.001504]
  3   0 350, 0.011287 [0.001026/41.020307] [ 300/0.001504]
Epoch 0 done. Evaluation:
(50000, 50000)
(8527, 10000)
  3   1  50, 0.001573 [0.000879/40.997589] [ 391/0.001504]
  3   1 100, 0.003125 [0.001677/40.985098] [ 441/0.001504]
  3   1 150, 0.004752 [0.000695/40.972619] [ 491/0.001504]
  3   1 200, 0.006315 [0.001013/40.960133] [ 541/0.001504]
  3   1 250, 0.007906 [0.001076/40.947659] [ 591/0.001504]
  3   1 300, 0.009446 [0.000549/40.935181] [ 641/0.001504]
  3   1 350, 0.011143 [0.001514/40.922728] [ 691/0.001504]
Epoch 1 done. Evaluation:
(50000, 50000)
(8521, 10000)
  3   2  50, 0.001626 [0.002146/40.900044] [ 782/0.001504]
  3   2 100, 0.003344 [0.002835/40.887603] [ 832/0.001504]
  3   2 150, 0.004982 [0.000835/40.875154] [ 882/0.001504]
  3   2 200, 0.006720 [0.000658/40.862724] [ 932/0.001504]
  3   2 250, 0.008339 [0.001108/40.850283] [ 982/0.001504]
  3   2 300, 0.009833 [0.000879/40.837831] [1032/0.001504]
  3   2 350, 0.011526 [0.003455/40.825404] [1082/0.001504]
Epoch 2 done. Evaluation:
(50000, 50000)
(8525, 10000)
  3   3  50, 0.001804 [0.000560/40.802803] [1173/0.001504]
  3   3 100, 0.003460 [0.001500/40.790388] [1223/0.001504]
  3   3 150, 0.005068 [0.001462/40.777965] [1273/0.001504]
  3   3 200, 0.006686 [0.000611/40.765554] [1323/0.001504]
  3   3 250, 0.008330 [0.000867/40.753154] [1373/0.001504]
  3   3 300, 0.010038 [0.000655/40.740759] [1423/0.001504]
  3   3 350, 0.011578 [0.000946/40.728350] [1473/0.001504]
Epoch 3 done. Evaluation:
(50000, 50000)
(8519, 10000)
  3   4  50, 0.001701 [0.000755/40.705808] [1564/0.001504]
  3   4 100, 0.003296 [0.000969/40.693416] [1614/0.001504]
  3   4 150, 0.004918 [0.000760/40.681034] [1664/0.001504]
