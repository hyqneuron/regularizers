Sequential (
  (conv1_1): Sequential (
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (conv1_2): Sequential (
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (pool1): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
  (conv2_1): Sequential (
    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (conv2_2): Sequential (
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (pool2): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
  (conv3_1): Sequential (
    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (conv3_2): Sequential (
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (pool3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
  (conv4_1): Sequential (
    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (conv4_2): Sequential (
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (pool4): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
  (conv5_1): Sequential (
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (conv5_2): Sequential (
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (pool5): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
  (fc6): Sequential (
    (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (logit): Conv2d(256, 10, kernel_size=(1, 1), stride=(1, 1))
  (flatter): Flatten()
)
{'L1_decay': 5e-06,
 'batch_size': 128,
 'force_name': False,
 'graphfolder': 'logs/exp3_graphs/',
 'learning_rate': 0.1,
 'logfile': 'logs/exp3.log',
 'mode': '',
 'name': 'exp3',
 'num_base': 32,
 'optimizer': 'SGD',
 'weight_decay': 0.002}
Decayed training with schedule: [20, 20, 20, 20, 20]
  0   0  50, 1.808919 [0.438427/71.475433] [   0/1.808919]
  0   0 100, 3.312066 [0.391868/70.807835] [  50/1.808919]
  0   0 150, 4.681382 [0.373836/70.148484] [ 100/1.808919]
  0   0 200, 5.931256 [0.322858/69.493829] [ 150/1.808919]
  0   0 250, 7.106478 [0.318494/68.843427] [ 200/1.808919]
  0   0 300, 8.202425 [0.326351/68.199015] [ 250/1.808919]
  0   0 350, 9.251824 [0.274423/67.560839] [ 300/1.808919]
Epoch 0 done. Evaluation:
(26700, 50000)
(6002, 10000)
  0   1  50, 0.912879 [0.337587/66.422555] [   0/0.912879]
  0   1 100, 1.804844 [0.358207/65.806343] [  50/0.912879]
  0   1 150, 2.679149 [0.308655/65.195189] [ 100/0.912879]
  0   1 200, 3.514831 [0.303410/64.588129] [ 150/0.912879]
  0   1 250, 4.366253 [0.343831/63.986133] [ 200/0.912879]
  0   1 300, 5.165053 [0.305186/63.390863] [ 250/0.912879]
  0   1 350, 5.962970 [0.314280/62.799475] [ 300/0.912879]
Epoch 1 done. Evaluation:
(34921, 50000)
(7017, 10000)
  0   2  50, 0.713530 [0.358706/61.743196] [   0/0.713530]
  0   2 100, 1.400614 [0.266059/61.176245] [  50/0.713530]
  0   2 150, 2.108501 [0.337965/60.612045] [ 100/0.713530]
  0   2 200, 2.779413 [0.286272/60.054086] [ 150/0.713530]
  0   2 250, 3.456695 [0.315627/59.500013] [ 200/0.713530]
  0   2 300, 4.134697 [0.294116/58.951356] [ 250/0.713530]
  0   2 350, 4.796535 [0.313751/58.406144] [ 300/0.713530]
Epoch 2 done. Evaluation:
(38063, 50000)
(7287, 10000)
  0   3  50, 0.578355 [0.288258/57.435489] [   0/0.578355]
  0   3 100, 1.168988 [0.350025/56.916230] [  50/0.578355]
  0   3 150, 1.777021 [0.281925/56.399824] [ 100/0.578355]
  0   3 200, 2.369880 [0.286102/55.886952] [ 150/0.578355]
  0   3 250, 2.964558 [0.274045/55.378833] [ 200/0.578355]
  0   3 300, 3.562871 [0.331110/54.876796] [ 250/0.578355]
  0   3 350, 4.131945 [0.276877/54.381136] [ 300/0.578355]
Epoch 3 done. Evaluation:
(39633, 50000)
(7256, 10000)
  0   4  50, 0.506820 [0.342061/53.496219] [   0/0.506820]
  0   4 100, 0.993513 [0.273286/53.017620] [  50/0.506820]
  0   4 150, 1.515573 [0.309520/52.545951] [ 100/0.506820]
  0   4 200, 2.047386 [0.373062/52.079789] [ 150/0.506820]
  0   4 250, 2.592519 [0.303521/51.616033] [ 200/0.506820]
  0   4 300, 3.115020 [0.302579/51.161492] [ 250/0.506820]
  0   4 350, 3.632305 [0.307375/50.708387] [ 300/0.506820]
Epoch 4 done. Evaluation:
(40956, 50000)
(7682, 10000)
  0   5  50, 0.442308 [0.304138/49.895454] [   0/0.442308]
  0   5 100, 0.915565 [0.315052/49.461972] [  50/0.442308]
  0   5 150, 1.388277 [0.324652/49.033902] [ 100/0.442308]
  0   5 200, 1.856721 [0.317668/48.609355] [ 150/0.442308]
  0   5 250, 2.333303 [0.260269/48.184670] [ 200/0.442308]
  0   5 300, 2.809757 [0.345878/47.768177] [ 250/0.442308]
  0   5 350, 3.304923 [0.269158/47.357030] [ 300/0.442308]
Epoch 5 done. Evaluation:
(41874, 50000)
(7811, 10000)
  0   6  50, 0.387929 [0.372585/46.621194] [   0/0.387929]
  0   6 100, 0.826871 [0.362724/46.226514] [  50/0.387929]
  0   6 150, 1.247922 [0.367101/45.836198] [ 100/0.387929]
  0   6 200, 1.677690 [0.342270/45.453789] [ 150/0.387929]
  0   6 250, 2.127940 [0.328296/45.072485] [ 200/0.387929]
  0   6 300, 2.546718 [0.368063/44.693235] [ 250/0.387929]
  0   6 350, 2.995503 [0.333449/44.317710] [ 300/0.387929]
Epoch 6 done. Evaluation:
(42526, 50000)
(7027, 10000)
  0   7  50, 0.379748 [0.390639/43.651197] [   0/0.379748]
  0   7 100, 0.753288 [0.347006/43.294078] [  50/0.379748]
  0   7 150, 1.142259 [0.371979/42.941183] [ 100/0.379748]
  0   7 200, 1.527306 [0.371506/42.595668] [ 150/0.379748]
  0   7 250, 1.922848 [0.312979/42.249277] [ 200/0.379748]
  0   7 300, 2.348883 [0.319879/41.907666] [ 250/0.379748]
  0   7 350, 2.773838 [0.372663/41.571101] [ 300/0.379748]
Epoch 7 done. Evaluation:
(43121, 50000)
(7883, 10000)
  0   8  50, 0.337685 [0.299408/40.967414] [   0/0.337685]
  0   8 100, 0.683952 [0.305977/40.642953] [  50/0.337685]
  0   8 150, 1.056770 [0.398686/40.324275] [ 100/0.337685]
  0   8 200, 1.424888 [0.318335/40.007553] [ 150/0.337685]
  0   8 250, 1.791631 [0.408622/39.698303] [ 200/0.337685]
  0   8 300, 2.157147 [0.315868/39.391176] [ 250/0.337685]
  0   8 350, 2.558531 [0.368435/39.082093] [ 300/0.337685]
Epoch 8 done. Evaluation:
(43653, 50000)
(7506, 10000)
  0   9  50, 0.307198 [0.375075/38.536756] [   0/0.307198]
  0   9 100, 0.623083 [0.346787/38.245736] [  50/0.307198]
  0   9 150, 0.963073 [0.313633/37.961545] [ 100/0.307198]
  0   9 200, 1.316668 [0.344948/37.680215] [ 150/0.307198]
  0   9 250, 1.682238 [0.323538/37.396243] [ 200/0.307198]
  0   9 300, 2.037296 [0.411516/37.115346] [ 250/0.307198]
  0   9 350, 2.399443 [0.303243/36.840625] [ 300/0.307198]
Epoch 9 done. Evaluation:
(44114, 50000)
(7812, 10000)
  0  10  50, 0.296632 [0.310428/36.346005] [   0/0.296632]
  0  10 100, 0.590143 [0.340795/36.075287] [  50/0.296632]
  0  10 150, 0.888026 [0.357176/35.817287] [ 100/0.296632]
  0  10 200, 1.211941 [0.333761/35.563472] [ 150/0.296632]
  0  10 250, 1.533982 [0.263814/35.312688] [ 200/0.296632]
  0  10 300, 1.884178 [0.345860/35.063444] [ 250/0.296632]
  0  10 350, 2.236379 [0.320982/34.818552] [ 300/0.296632]
Epoch 10 done. Evaluation:
(44489, 50000)
(7851, 10000)
  0  11  50, 0.255939 [0.305914/34.375171] [   0/0.255939]
  0  11 100, 0.523800 [0.230146/34.134465] [  50/0.255939]
  0  11 150, 0.804548 [0.367295/33.900210] [ 100/0.255939]
  0  11 200, 1.114409 [0.307290/33.675028] [ 150/0.255939]
  0  11 250, 1.441832 [0.329875/33.452130] [ 200/0.255939]
  0  11 300, 1.760310 [0.320982/33.232418] [ 250/0.255939]
  0  11 350, 2.092325 [0.373096/33.011956] [ 300/0.255939]
Epoch 11 done. Evaluation:
(44862, 50000)
(7822, 10000)
  0  12  50, 0.273650 [0.397485/32.616270] [ 391/0.255939]
  0  12 100, 0.546177 [0.379069/32.403930] [ 441/0.255939]
  0  12 150, 0.837689 [0.384702/32.197794] [ 491/0.255939]
  0  12 200, 1.145850 [0.295025/31.997392] [ 541/0.255939]
  0  12 250, 1.453876 [0.362392/31.795232] [ 591/0.255939]
  0  12 300, 1.750058 [0.270952/31.598405] [ 641/0.255939]
  0  12 350, 2.064375 [0.426059/31.401666] [ 691/0.255939]
Epoch 12 done. Evaluation:
(44979, 50000)
(7803, 10000)
  0  13  50, 0.239863 [0.341425/31.052426] [   0/0.239863]
  0  13 100, 0.508426 [0.402309/30.864251] [  50/0.239863]
  0  13 150, 0.792637 [0.392643/30.682739] [ 100/0.239863]
  0  13 200, 1.068860 [0.373341/30.501422] [ 150/0.239863]
  0  13 250, 1.371201 [0.309618/30.324114] [ 200/0.239863]
  0  13 300, 1.683471 [0.314561/30.157430] [ 250/0.239863]
  0  13 350, 1.988833 [0.320572/29.993153] [ 300/0.239863]
Epoch 13 done. Evaluation:
(45149, 50000)
(7702, 10000)
  0  14  50, 0.232737 [0.334850/29.676721] [   0/0.232737]
  0  14 100, 0.488113 [0.302368/29.508958] [  50/0.232737]
  0  14 150, 0.748843 [0.370696/29.348356] [ 100/0.232737]
  0  14 200, 1.024284 [0.398070/29.195728] [ 150/0.232737]
  0  14 250, 1.313923 [0.387283/29.039791] [ 200/0.232737]
  0  14 300, 1.594028 [0.347192/28.886736] [ 250/0.232737]
  0  14 350, 1.888899 [0.416934/28.739437] [ 300/0.232737]
Epoch 14 done. Evaluation:
(45333, 50000)
(7980, 10000)
  0  15  50, 0.223141 [0.280855/28.461615] [   0/0.223141]
  0  15 100, 0.467378 [0.384694/28.320532] [  50/0.223141]
  0  15 150, 0.748668 [0.329389/28.182904] [ 100/0.223141]
  0  15 200, 1.003732 [0.336332/28.044989] [ 150/0.223141]
  0  15 250, 1.274794 [0.335809/27.908839] [ 200/0.223141]
  0  15 300, 1.556953 [0.409364/27.783888] [ 250/0.223141]
  0  15 350, 1.856262 [0.389956/27.655031] [ 300/0.223141]
Epoch 15 done. Evaluation:
(45505, 50000)
(6529, 10000)
  0  16  50, 0.219038 [0.249509/27.411838] [   0/0.219038]
  0  16 100, 0.445397 [0.411437/27.285934] [  50/0.219038]
  0  16 150, 0.698464 [0.346858/27.163670] [ 100/0.219038]
  0  16 200, 0.964620 [0.403755/27.047821] [ 150/0.219038]
  0  16 250, 1.222609 [0.256061/26.926707] [ 200/0.219038]
  0  16 300, 1.480960 [0.436118/26.805981] [ 250/0.219038]
  0  16 350, 1.758052 [0.373763/26.693051] [ 300/0.219038]
Epoch 16 done. Evaluation:
(45639, 50000)
(8159, 10000)
  0  17  50, 0.210544 [0.334313/26.483456] [   0/0.210544]
  0  17 100, 0.432615 [0.301906/26.370074] [  50/0.210544]
  0  17 150, 0.665598 [0.323796/26.265570] [ 100/0.210544]
  0  17 200, 0.915884 [0.542384/26.161992] [ 150/0.210544]
  0  17 250, 1.195495 [0.438002/26.078042] [ 200/0.210544]
  0  17 300, 1.472651 [0.453815/25.979596] [ 250/0.210544]
  0  17 350, 1.741284 [0.432084/25.884694] [ 300/0.210544]
Epoch 17 done. Evaluation:
(45676, 50000)
(8026, 10000)
  0  18  50, 0.205389 [0.426824/25.698357] [   0/0.205389]
  0  18 100, 0.430015 [0.354364/25.597566] [  50/0.205389]
  0  18 150, 0.662533 [0.331992/25.503164] [ 100/0.205389]
  0  18 200, 0.902240 [0.378962/25.409946] [ 150/0.205389]
  0  18 250, 1.154044 [0.481573/25.329890] [ 200/0.205389]
  0  18 300, 1.417025 [0.386693/25.246865] [ 250/0.205389]
  0  18 350, 1.681564 [0.459856/25.171140] [ 300/0.205389]
Epoch 18 done. Evaluation:
(45901, 50000)
(7989, 10000)
  0  19  50, 0.206749 [0.480684/25.013458] [ 391/0.205389]
  0  19 100, 0.416144 [0.363042/24.930280] [ 441/0.205389]
  0  19 150, 0.631786 [0.358228/24.860148] [ 491/0.205389]
  0  19 200, 0.889836 [0.432196/24.804787] [ 541/0.205389]
  0  19 250, 1.146821 [0.474274/24.723216] [ 591/0.205389]
  0  19 300, 1.394691 [0.397745/24.645606] [ 641/0.205389]
  0  19 350, 1.659701 [0.437300/24.577087] [ 691/0.205389]
Epoch 19 done. Evaluation:
(45911, 50000)
(7872, 10000)
  1   0  50, 0.149454 [0.145444/24.442213] [   0/0.149454]
  1   0 100, 0.275046 [0.101242/24.359140] [  50/0.149454]
  1   0 150, 0.401304 [0.206817/24.278309] [ 100/0.149454]
  1   0 200, 0.529302 [0.199470/24.199141] [ 150/0.149454]
  1   0 250, 0.653425 [0.108797/24.121719] [ 200/0.149454]
  1   0 300, 0.779050 [0.110341/24.044207] [ 250/0.149454]
  1   0 350, 0.907855 [0.194001/23.968937] [ 300/0.149454]
Epoch 0 done. Evaluation:
(48028, 50000)
(8130, 10000)
  1   1  50, 0.076081 [0.124828/23.823828] [   0/0.076081]
  1   1 100, 0.160134 [0.147198/23.743386] [  50/0.076081]
  1   1 150, 0.237229 [0.050612/23.660765] [ 100/0.076081]
  1   1 200, 0.323871 [0.190153/23.582386] [ 150/0.076081]
  1   1 250, 0.414091 [0.183230/23.507257] [ 200/0.076081]
  1   1 300, 0.494447 [0.158043/23.430077] [ 250/0.076081]
  1   1 350, 0.581700 [0.157175/23.354012] [ 300/0.076081]
Epoch 1 done. Evaluation:
(48809, 50000)
(8528, 10000)
  1   2  50, 0.059076 [0.128598/23.210231] [   0/0.059076]
  1   2 100, 0.123356 [0.184221/23.132411] [  50/0.059076]
  1   2 150, 0.196807 [0.173822/23.056498] [ 100/0.059076]
  1   2 200, 0.279079 [0.129694/22.988531] [ 150/0.059076]
  1   2 250, 0.355098 [0.136921/22.918648] [ 200/0.059076]
  1   2 300, 0.441998 [0.238690/22.852477] [ 250/0.059076]
  1   2 350, 0.526946 [0.201249/22.788769] [ 300/0.059076]
Epoch 2 done. Evaluation:
(48845, 50000)
(8410, 10000)
  1   3  50, 0.066710 [0.081734/22.665237] [ 391/0.059076]
  1   3 100, 0.137801 [0.101849/22.596566] [ 441/0.059076]
  1   3 150, 0.212571 [0.120560/22.531380] [ 491/0.059076]
  1   3 200, 0.284476 [0.222386/22.465579] [ 541/0.059076]
  1   3 250, 0.361837 [0.171451/22.402533] [ 591/0.059076]
  1   3 300, 0.446417 [0.171653/22.347178] [ 641/0.059076]
  1   3 350, 0.531372 [0.189193/22.288269] [ 691/0.059076]
Epoch 3 done. Evaluation:
(48828, 50000)
(8260, 10000)
  1   4  50, 0.064060 [0.216111/22.179419] [ 782/0.059076]
  1   4 100, 0.138480 [0.137103/22.118797] [ 832/0.059076]
  1   4 150, 0.209159 [0.265643/22.056658] [ 882/0.059076]
  1   4 200, 0.277805 [0.127414/21.996402] [ 932/0.059076]
  1   4 250, 0.353947 [0.258320/21.941664] [ 982/0.059076]
  1   4 300, 0.436576 [0.289543/21.891946] [1032/0.059076]
  1   4 350, 0.544529 [0.274494/21.856037] [1082/0.059076]
Epoch 4 done. Evaluation:
(48751, 50000)
(8373, 10000)
  1   5  50, 0.082436 [0.238667/21.765205] [1173/0.059076]
  1   5 100, 0.155712 [0.128328/21.710118] [1223/0.059076]
  1   5 150, 0.230441 [0.159160/21.659571] [1273/0.059076]
  1   5 200, 0.313164 [0.255637/21.610798] [1323/0.059076]
  1   5 250, 0.425694 [0.251886/21.574606] [1373/0.059076]
  1   5 300, 0.529988 [0.192905/21.538437] [1423/0.059076]
  1   5 350, 0.641688 [0.262576/21.506874] [1473/0.059076]
Epoch 5 done. Evaluation:
(48509, 50000)
(7857, 10000)
  1   6  50, 0.083579 [0.178884/21.434957] [1564/0.059076]
  1   6 100, 0.162810 [0.223537/21.385992] [1614/0.059076]
  1   6 150, 0.255725 [0.170509/21.348720] [1664/0.059076]
  1   6 200, 0.364100 [0.130551/21.314347] [1714/0.059076]
  1   6 250, 0.476402 [0.204310/21.285114] [1764/0.059076]
  1   6 300, 0.576163 [0.175593/21.249490] [1814/0.059076]
  1   6 350, 0.687595 [0.296562/21.220534] [1864/0.059076]
Epoch 6 done. Evaluation:
(48375, 50000)
(8012, 10000)
  1   7  50, 0.084938 [0.143899/21.157769] [1955/0.059076]
  1   7 100, 0.176080 [0.247934/21.119217] [2005/0.059076]
  1   7 150, 0.267052 [0.174706/21.079362] [2055/0.059076]
  1   7 200, 0.359510 [0.244598/21.046471] [2105/0.059076]
  1   7 250, 0.476713 [0.353129/21.024855] [2155/0.059076]
  1   7 300, 0.605839 [0.302316/21.008432] [2205/0.059076]
  1   7 350, 0.724173 [0.222259/20.986237] [2255/0.059076]
Epoch 7 done. Evaluation:
(48305, 50000)
(8306, 10000)
  1   8  50, 0.083486 [0.197517/20.931231] [2346/0.059076]
  1   8 100, 0.180708 [0.283936/20.900689] [2396/0.059076]
  1   8 150, 0.266175 [0.201700/20.866750] [2446/0.059076]
  1   8 200, 0.368137 [0.190499/20.842114] [2496/0.059076]
  1   8 250, 0.481603 [0.238917/20.822122] [2546/0.059076]
  1   8 300, 0.594980 [0.223467/20.797831] [2596/0.059076]
  1   8 350, 0.720143 [0.300221/20.785073] [2646/0.059076]
Epoch 8 done. Evaluation:
(48220, 50000)
(7497, 10000)
  1   9  50, 0.108633 [0.224581/20.752377] [2737/0.059076]
  1   9 100, 0.225408 [0.251339/20.729586] [2787/0.059076]
  1   9 150, 0.319665 [0.294298/20.692049] [2837/0.059076]
  1   9 200, 0.431978 [0.207605/20.670029] [2887/0.059076]
  1   9 250, 0.553419 [0.176806/20.647782] [2937/0.059076]
  1   9 300, 0.677278 [0.280853/20.631772] [2987/0.059076]
  1   9 350, 0.788005 [0.227103/20.604650] [3037/0.059076]
Epoch 9 done. Evaluation:
(48147, 50000)
(7882, 10000)
  1  10  50, 0.090571 [0.180234/20.562322] [3128/0.059076]
  1  10 100, 0.187810 [0.211529/20.535719] [3178/0.059076]
  1  10 150, 0.292051 [0.123041/20.513029] [3228/0.059076]
  1  10 200, 0.412376 [0.334684/20.501274] [3278/0.059076]
  1  10 250, 0.525474 [0.232566/20.485535] [3328/0.059076]
  1  10 300, 0.634776 [0.223106/20.465543] [3378/0.059076]
  1  10 350, 0.783601 [0.312980/20.468019] [3428/0.059076]
Epoch 10 done. Evaluation:
(48130, 50000)
(8070, 10000)
  1  11  50, 0.106710 [0.222707/20.434794] [3519/0.059076]
  1  11 100, 0.203197 [0.204557/20.410068] [3569/0.059076]
  1  11 150, 0.302935 [0.172616/20.378351] [3619/0.059076]
  1  11 200, 0.416537 [0.274837/20.360586] [3669/0.059076]
  1  11 250, 0.540272 [0.286210/20.353887] [3719/0.059076]
  1  11 300, 0.662486 [0.319855/20.339656] [3769/0.059076]
  1  11 350, 0.791153 [0.320839/20.330552] [3819/0.059076]
Epoch 11 done. Evaluation:
(48105, 50000)
(8158, 10000)
  1  12  50, 0.101274 [0.300903/20.307113] [3910/0.059076]
  1  12 100, 0.211545 [0.183977/20.286340] [3960/0.059076]
  1  12 150, 0.318206 [0.197054/20.265021] [4010/0.059076]
  1  12 200, 0.432958 [0.226674/20.248309] [4060/0.059076]
  1  12 250, 0.539184 [0.216945/20.228065] [4110/0.059076]
  1  12 300, 0.658763 [0.302425/20.212935] [4160/0.059076]
  1  12 350, 0.794423 [0.216685/20.207241] [4210/0.059076]
Epoch 12 done. Evaluation:
(48117, 50000)
(7993, 10000)
  1  13  50, 0.090252 [0.140464/20.176256] [4301/0.059076]
  1  13 100, 0.178256 [0.145730/20.150014] [4351/0.059076]
  1  13 150, 0.288177 [0.240634/20.135843] [4401/0.059076]
  1  13 200, 0.398409 [0.095858/20.123162] [4451/0.059076]
  1  13 250, 0.503722 [0.189167/20.102556] [4501/0.059076]
  1  13 300, 0.624956 [0.194612/20.094560] [4551/0.059076]
  1  13 350, 0.757781 [0.283418/20.093696] [4601/0.059076]
Epoch 13 done. Evaluation:
(48244, 50000)
(8197, 10000)
  1  14  50, 0.093687 [0.242746/20.061158] [4692/0.059076]
  1  14 100, 0.195839 [0.142087/20.043439] [4742/0.059076]
  1  14 150, 0.305329 [0.219182/20.033369] [4792/0.059076]
  1  14 200, 0.423257 [0.226875/20.028767] [4842/0.059076]
  1  14 250, 0.548234 [0.282253/20.021150] [4892/0.059076]
  1  14 300, 0.661444 [0.278871/20.004601] [4942/0.059076]
  1  14 350, 0.796583 [0.306345/20.003798] [4992/0.059076]
Epoch 14 done. Evaluation:
(48095, 50000)
(7274, 10000)
  1  15  50, 0.109587 [0.179817/19.985003] [5083/0.059076]
  1  15 100, 0.215177 [0.103993/19.969036] [5133/0.059076]
  1  15 150, 0.315224 [0.207530/19.947412] [5183/0.059076]
  1  15 200, 0.418784 [0.294096/19.932798] [5233/0.059076]
  1  15 250, 0.548751 [0.256888/19.936022] [5283/0.059076]
  1  15 300, 0.668492 [0.208692/19.929764] [5333/0.059076]
  1  15 350, 0.813361 [0.192996/19.930299] [5383/0.059076]
Epoch 15 done. Evaluation:
(48034, 50000)
(8335, 10000)
  1  16  50, 0.081560 [0.152326/19.901717] [5474/0.059076]
  1  16 100, 0.168934 [0.289613/19.878203] [5524/0.059076]
  1  16 150, 0.274564 [0.222734/19.867397] [5574/0.059076]
  1  16 200, 0.396338 [0.310703/19.861950] [5624/0.059076]
  1  16 250, 0.512448 [0.313418/19.854567] [5674/0.059076]
  1  16 300, 0.642589 [0.344304/19.861530] [5724/0.059076]
  1  16 350, 0.778812 [0.256183/19.862643] [5774/0.059076]
Epoch 16 done. Evaluation:
(48132, 50000)
(8224, 10000)
  1  17  50, 0.096074 [0.234060/19.838963] [5865/0.059076]
  1  17 100, 0.195377 [0.217266/19.817814] [5915/0.059076]
  1  17 150, 0.314266 [0.243985/19.806948] [5965/0.059076]
  1  17 200, 0.429538 [0.298430/19.798585] [6015/0.059076]
  1  17 250, 0.552593 [0.302819/19.793172] [6065/0.059076]
  1  17 300, 0.676599 [0.213289/19.782933] [6115/0.059076]
  1  17 350, 0.797688 [0.202860/19.781705] [6165/0.059076]
Epoch 17 done. Evaluation:
(48084, 50000)
(8135, 10000)
  1  18  50, 0.117963 [0.206830/19.787625] [6256/0.059076]
  1  18 100, 0.222398 [0.174296/19.772658] [6306/0.059076]
  1  18 150, 0.333169 [0.252038/19.760126] [6356/0.059076]
  1  18 200, 0.450161 [0.306856/19.749542] [6406/0.059076]
  1  18 250, 0.567852 [0.196052/19.736702] [6456/0.059076]
  1  18 300, 0.681122 [0.307722/19.727440] [6506/0.059076]
  1  18 350, 0.791702 [0.206507/19.713644] [6556/0.059076]
Epoch 18 done. Evaluation:
(48195, 50000)
(8189, 10000)
  1  19  50, 0.093653 [0.107658/19.690338] [6647/0.059076]
  1  19 100, 0.190619 [0.244268/19.680470] [6697/0.059076]
  1  19 150, 0.290267 [0.201100/19.666772] [6747/0.059076]
  1  19 200, 0.403563 [0.247727/19.664218] [6797/0.059076]
  1  19 250, 0.533089 [0.175133/19.662407] [6847/0.059076]
  1  19 300, 0.644298 [0.160950/19.653701] [6897/0.059076]
  1  19 350, 0.769956 [0.312889/19.655902] [6947/0.059076]
Epoch 19 done. Evaluation:
(48185, 50000)
(8039, 10000)
  2   0  50, 0.071165 [0.090491/19.627153] [7038/0.059076]
  2   0 100, 0.121374 [0.071615/19.594662] [7088/0.059076]
  2   0 150, 0.169363 [0.028151/19.562869] [7138/0.059076]
  2   0 200, 0.212510 [0.033633/19.531018] [7188/0.059076]
  2   0 250, 0.255936 [0.129367/19.499539] [7238/0.059076]
  2   0 300, 0.301512 [0.018484/19.467140] [7288/0.059076]
  2   0 350, 0.345250 [0.113224/19.435480] [7338/0.059076]
Epoch 0 done. Evaluation:
(49335, 50000)
(8689, 10000)
  2   1  50, 0.027294 [0.035726/19.372764] [   0/0.027294]
  2   1 100, 0.050757 [0.063637/19.335691] [  50/0.027294]
  2   1 150, 0.074302 [0.005711/19.299012] [ 100/0.027294]
  2   1 200, 0.099871 [0.043465/19.262393] [ 150/0.027294]
  2   1 250, 0.125530 [0.028692/19.226045] [ 200/0.027294]
  2   1 300, 0.150618 [0.022416/19.190434] [ 250/0.027294]
  2   1 350, 0.174269 [0.037177/19.154083] [ 300/0.027294]
Epoch 1 done. Evaluation:
(49747, 50000)
(8762, 10000)
  2   2  50, 0.018170 [0.091156/19.088234] [   0/0.018170]
  2   2 100, 0.032592 [0.024911/19.049316] [  50/0.018170]
  2   2 150, 0.048529 [0.111666/19.011325] [ 100/0.018170]
  2   2 200, 0.064773 [0.022676/18.973881] [ 150/0.018170]
  2   2 250, 0.083714 [0.028416/18.936931] [ 200/0.018170]
  2   2 300, 0.107640 [0.074384/18.902805] [ 250/0.018170]
  2   2 350, 0.128381 [0.034093/18.868218] [ 300/0.018170]
Epoch 2 done. Evaluation:
(49816, 50000)
(8608, 10000)
  2   3  50, 0.013900 [0.026381/18.800854] [   0/0.013900]
  2   3 100, 0.032394 [0.005559/18.764948] [  50/0.013900]
  2   3 150, 0.048452 [0.090018/18.728254] [ 100/0.013900]
  2   3 200, 0.061826 [0.018531/18.690781] [ 150/0.013900]
  2   3 250, 0.075513 [0.037037/18.653237] [ 200/0.013900]
  2   3 300, 0.090851 [0.026307/18.617294] [ 250/0.013900]
  2   3 350, 0.106391 [0.047466/18.581586] [ 300/0.013900]
Epoch 3 done. Evaluation:
(49878, 50000)
(8732, 10000)
  2   4  50, 0.011669 [0.017946/18.514208] [   0/0.011669]
  2   4 100, 0.021254 [0.016470/18.475400] [  50/0.011669]
  2   4 150, 0.030416 [0.008057/18.436558] [ 100/0.011669]
  2   4 200, 0.041415 [0.012668/18.398120] [ 150/0.011669]
  2   4 250, 0.052326 [0.004537/18.360202] [ 200/0.011669]
  2   4 300, 0.063500 [0.052374/18.322618] [ 250/0.011669]
  2   4 350, 0.073533 [0.006169/18.284942] [ 300/0.011669]
Epoch 4 done. Evaluation:
(49949, 50000)
(8744, 10000)
  2   5  50, 0.009100 [0.034420/18.216806] [   0/0.009100]
  2   5 100, 0.019601 [0.065439/18.180088] [  50/0.009100]
  2   5 150, 0.028660 [0.019402/18.142260] [ 100/0.009100]
  2   5 200, 0.037502 [0.009946/18.104488] [ 150/0.009100]
  2   5 250, 0.045771 [0.006566/18.066519] [ 200/0.009100]
  2   5 300, 0.054658 [0.038868/18.029433] [ 250/0.009100]
  2   5 350, 0.064535 [0.004998/17.992853] [ 300/0.009100]
Epoch 5 done. Evaluation:
(49961, 50000)
(8781, 10000)
  2   6  50, 0.008289 [0.010062/17.924399] [   0/0.008289]
  2   6 100, 0.016151 [0.026762/17.886655] [  50/0.008289]
  2   6 150, 0.023212 [0.008455/17.848472] [ 100/0.008289]
  2   6 200, 0.031947 [0.019714/17.811382] [ 150/0.008289]
  2   6 250, 0.039799 [0.008029/17.773899] [ 200/0.008289]
  2   6 300, 0.046856 [0.022191/17.735965] [ 250/0.008289]
  2   6 350, 0.054321 [0.003882/17.698643] [ 300/0.008289]
Epoch 6 done. Evaluation:
(49985, 50000)
(8794, 10000)
  2   7  50, 0.006801 [0.024697/17.630396] [   0/0.006801]
  2   7 100, 0.013557 [0.004365/17.592856] [  50/0.006801]
  2   7 150, 0.020500 [0.007725/17.555504] [ 100/0.006801]
  2   7 200, 0.027985 [0.005015/17.518786] [ 150/0.006801]
  2   7 250, 0.035485 [0.010060/17.481393] [ 200/0.006801]
  2   7 300, 0.043336 [0.006222/17.445152] [ 250/0.006801]
  2   7 350, 0.050584 [0.002825/17.408613] [ 300/0.006801]
Epoch 7 done. Evaluation:
(49986, 50000)
(8787, 10000)
  2   8  50, 0.010248 [0.011160/17.344247] [ 391/0.006801]
  2   8 100, 0.019164 [0.026311/17.309077] [ 441/0.006801]
  2   8 150, 0.027477 [0.013527/17.273720] [ 491/0.006801]
  2   8 200, 0.037801 [0.002871/17.240174] [ 541/0.006801]
  2   8 250, 0.049271 [0.016427/17.207579] [ 591/0.006801]
  2   8 300, 0.059263 [0.042011/17.174110] [ 641/0.006801]
  2   8 350, 0.069999 [0.039526/17.141066] [ 691/0.006801]
Epoch 8 done. Evaluation:
(49941, 50000)
(8355, 10000)
  2   9  50, 0.010827 [0.009315/17.084596] [ 782/0.006801]
  2   9 100, 0.020459 [0.029684/17.050910] [ 832/0.006801]
  2   9 150, 0.033683 [0.004748/17.020201] [ 882/0.006801]
  2   9 200, 0.043287 [0.025463/16.986765] [ 932/0.006801]
  2   9 250, 0.055190 [0.020183/16.956855] [ 982/0.006801]
  2   9 300, 0.066459 [0.003070/16.924963] [1032/0.006801]
  2   9 350, 0.075474 [0.028019/16.891623] [1082/0.006801]
Epoch 9 done. Evaluation:
(49943, 50000)
(8597, 10000)
  2  10  50, 0.008998 [0.009942/16.832758] [1173/0.006801]
  2  10 100, 0.016450 [0.015262/16.798227] [1223/0.006801]
  2  10 150, 0.024060 [0.022830/16.763994] [1273/0.006801]
  2  10 200, 0.032458 [0.018377/16.730797] [1323/0.006801]
  2  10 250, 0.041098 [0.003884/16.698586] [1373/0.006801]
  2  10 300, 0.049728 [0.049009/16.665530] [1423/0.006801]
  2  10 350, 0.057930 [0.006614/16.632841] [1473/0.006801]
Epoch 10 done. Evaluation:
(49977, 50000)
(8730, 10000)
  2  11  50, 0.007420 [0.007264/16.573133] [1564/0.006801]
  2  11 100, 0.016402 [0.002949/16.541408] [1614/0.006801]
  2  11 150, 0.027197 [0.041705/16.510746] [1664/0.006801]
  2  11 200, 0.035453 [0.003705/16.478126] [1714/0.006801]
  2  11 250, 0.043880 [0.007452/16.446138] [1764/0.006801]
  2  11 300, 0.052927 [0.008753/16.415052] [1814/0.006801]
  2  11 350, 0.063219 [0.084761/16.385492] [1864/0.006801]
Epoch 11 done. Evaluation:
(49961, 50000)
(8673, 10000)
  2  12  50, 0.010668 [0.133708/16.337236] [1955/0.006801]
  2  12 100, 0.028745 [0.081062/16.313460] [2005/0.006801]
  2  12 150, 0.047218 [0.151003/16.292596] [2055/0.006801]
  2  12 200, 0.079768 [0.171024/16.285126] [2105/0.006801]
  2  12 250, 0.125274 [0.105893/16.282957] [2155/0.006801]
  2  12 300, 0.178313 [0.107053/16.285924] [2205/0.006801]
  2  12 350, 0.242166 [0.165952/16.297815] [2255/0.006801]
Epoch 12 done. Evaluation:
(49528, 50000)
(8393, 10000)
  2  13  50, 0.063753 [0.222338/16.304681] [2346/0.006801]
  2  13 100, 0.114034 [0.114563/16.301567] [2396/0.006801]
  2  13 150, 0.178704 [0.117453/16.311253] [2446/0.006801]
  2  13 200, 0.256262 [0.041654/16.321780] [2496/0.006801]
  2  13 250, 0.325316 [0.201585/16.325834] [2546/0.006801]
  2  13 300, 0.397656 [0.119485/16.333944] [2596/0.006801]
  2  13 350, 0.463200 [0.158222/16.336191] [2646/0.006801]
Epoch 13 done. Evaluation:
(48935, 50000)
(8523, 10000)
  2  14  50, 0.051848 [0.093468/16.340829] [2737/0.006801]
  2  14 100, 0.113446 [0.124684/16.342369] [2787/0.006801]
  2  14 150, 0.173879 [0.203988/16.344648] [2837/0.006801]
  2  14 200, 0.254870 [0.142123/16.354692] [2887/0.006801]
  2  14 250, 0.325883 [0.199534/16.357596] [2937/0.006801]
  2  14 300, 0.388360 [0.151510/16.357563] [2987/0.006801]
  2  14 350, 0.468732 [0.219551/16.364903] [3037/0.006801]
Epoch 14 done. Evaluation:
(48975, 50000)
(8406, 10000)
  2  15  50, 0.061308 [0.188922/16.370039] [3128/0.006801]
  2  15 100, 0.122790 [0.075329/16.368268] [3178/0.006801]
  2  15 150, 0.172777 [0.128753/16.362514] [3228/0.006801]
  2  15 200, 0.234158 [0.178242/16.362830] [3278/0.006801]
  2  15 250, 0.302142 [0.127797/16.364898] [3328/0.006801]
  2  15 300, 0.380797 [0.219204/16.370358] [3378/0.006801]
  2  15 350, 0.458829 [0.194707/16.373874] [3428/0.006801]
Epoch 15 done. Evaluation:
(48992, 50000)
(8337, 10000)
  2  16  50, 0.059824 [0.135387/16.374864] [3519/0.006801]
  2  16 100, 0.114992 [0.152734/16.371018] [3569/0.006801]
  2  16 150, 0.171147 [0.099165/16.367274] [3619/0.006801]
  2  16 200, 0.248087 [0.152274/16.373893] [3669/0.006801]
  2  16 250, 0.322215 [0.185116/16.378464] [3719/0.006801]
  2  16 300, 0.389731 [0.164202/16.377621] [3769/0.006801]
  2  16 350, 0.447141 [0.230271/16.376292] [3819/0.006801]
Epoch 16 done. Evaluation:
(49007, 50000)
(8374, 10000)
  2  17  50, 0.049519 [0.235127/16.372474] [3910/0.006801]
  2  17 100, 0.107139 [0.138878/16.371232] [3960/0.006801]
  2  17 150, 0.173195 [0.145071/16.375508] [4010/0.006801]
  2  17 200, 0.255145 [0.090881/16.380586] [4060/0.006801]
  2  17 250, 0.315938 [0.157314/16.377581] [4110/0.006801]
  2  17 300, 0.390827 [0.188671/16.384567] [4160/0.006801]
  2  17 350, 0.458312 [0.140638/16.385010] [4210/0.006801]
Epoch 17 done. Evaluation:
(49004, 50000)
(8612, 10000)
  2  18  50, 0.050708 [0.055311/16.377130] [4301/0.006801]
  2  18 100, 0.103022 [0.084971/16.371109] [4351/0.006801]
  2  18 150, 0.171523 [0.134696/16.372997] [4401/0.006801]
  2  18 200, 0.231272 [0.198817/16.371724] [4451/0.006801]
  2  18 250, 0.287601 [0.153560/16.368818] [4501/0.006801]
  2  18 300, 0.350135 [0.101769/16.368111] [4551/0.006801]
  2  18 350, 0.418397 [0.102250/16.372959] [4601/0.006801]
Epoch 18 done. Evaluation:
(49061, 50000)
(8178, 10000)
  2  19  50, 0.056975 [0.165088/16.379402] [4692/0.006801]
  2  19 100, 0.111210 [0.128378/16.374762] [4742/0.006801]
  2  19 150, 0.164033 [0.130400/16.371963] [4792/0.006801]
  2  19 200, 0.223000 [0.036281/16.372251] [4842/0.006801]
  2  19 250, 0.290211 [0.089019/16.375637] [4892/0.006801]
  2  19 300, 0.338937 [0.052863/16.370117] [4942/0.006801]
  2  19 350, 0.401854 [0.114073/16.370294] [4992/0.006801]
Epoch 19 done. Evaluation:
(49113, 50000)
(8130, 10000)
  3   0  50, 0.047660 [0.056381/16.364049] [5083/0.006801]
  3   0 100, 0.077262 [0.059618/16.351100] [5133/0.006801]
  3   0 150, 0.103117 [0.052608/16.338234] [5183/0.006801]
  3   0 200, 0.127707 [0.013930/16.325292] [5233/0.006801]
  3   0 250, 0.153010 [0.060395/16.312513] [5283/0.006801]
  3   0 300, 0.175856 [0.032434/16.299314] [5333/0.006801]
  3   0 350, 0.198069 [0.027853/16.285892] [5383/0.006801]
Epoch 0 done. Evaluation:
(49668, 50000)
(8726, 10000)
  3   1  50, 0.015546 [0.004020/16.259851] [5474/0.006801]
  3   1 100, 0.027863 [0.013866/16.244740] [5524/0.006801]
  3   1 150, 0.042244 [0.033321/16.229904] [5574/0.006801]
  3   1 200, 0.057359 [0.029193/16.215403] [5624/0.006801]
  3   1 250, 0.070941 [0.017246/16.200553] [5674/0.006801]
  3   1 300, 0.084036 [0.003773/16.185658] [5724/0.006801]
  3   1 350, 0.099971 [0.016312/16.171452] [5774/0.006801]
Epoch 1 done. Evaluation:
(49891, 50000)
(8636, 10000)
  3   2  50, 0.011157 [0.010399/16.143907] [5865/0.006801]
  3   2 100, 0.021987 [0.002777/16.128632] [5915/0.006801]
  3   2 150, 0.031637 [0.008077/16.112984] [5965/0.006801]
  3   2 200, 0.042343 [0.015453/16.097662] [6015/0.006801]
  3   2 250, 0.053633 [0.057497/16.082569] [6065/0.006801]
  3   2 300, 0.065717 [0.024179/16.067733] [6115/0.006801]
  3   2 350, 0.075297 [0.003428/16.052107] [6165/0.006801]
Epoch 2 done. Evaluation:
(49937, 50000)
(8740, 10000)
  3   3  50, 0.009703 [0.002142/16.024751] [6256/0.006801]
  3   3 100, 0.019290 [0.002062/16.009223] [6306/0.006801]
  3   3 150, 0.028855 [0.007504/15.993691] [6356/0.006801]
  3   3 200, 0.039934 [0.003240/15.978398] [6406/0.006801]
  3   3 250, 0.048956 [0.007870/15.962864] [6456/0.006801]
  3   3 300, 0.058709 [0.001910/15.947267] [6506/0.006801]
  3   3 350, 0.067192 [0.004498/15.931526] [6556/0.006801]
Epoch 3 done. Evaluation:
(49970, 50000)
(8782, 10000)
  3   4  50, 0.007491 [0.005990/15.902765] [6647/0.006801]
  3   4 100, 0.015200 [0.005722/15.886908] [6697/0.006801]
  3   4 150, 0.023260 [0.001051/15.871147] [6747/0.006801]
  3   4 200, 0.032094 [0.003278/15.855631] [6797/0.006801]
  3   4 250, 0.040492 [0.004967/15.840087] [6847/0.006801]
  3   4 300, 0.048580 [0.020258/15.824441] [6897/0.006801]
  3   4 350, 0.056276 [0.001577/15.808676] [6947/0.006801]
Epoch 4 done. Evaluation:
(49980, 50000)
(8778, 10000)
  3   5  50, 0.007171 [0.021839/15.779816] [7038/0.006801]
  3   5 100, 0.015604 [0.007769/15.764163] [7088/0.006801]
  3   5 150, 0.023097 [0.012069/15.748374] [7138/0.006801]
  3   5 200, 0.030250 [0.002829/15.732563] [7188/0.006801]
  3   5 250, 0.037361 [0.001191/15.716710] [7238/0.006801]
  3   5 300, 0.045157 [0.001842/15.701103] [7288/0.006801]
  3   5 350, 0.053112 [0.001691/15.685473] [7338/0.006801]
Epoch 5 done. Evaluation:
(49990, 50000)
(8776, 10000)
  3   6  50, 0.007296 [0.003679/15.656897] [7429/0.006801]
  3   6 100, 0.014035 [0.012050/15.641059] [7479/0.006801]
  3   6 150, 0.020603 [0.001101/15.625182] [7529/0.006801]
  3   6 200, 0.027516 [0.001918/15.609453] [7579/0.006801]
  3   6 250, 0.034113 [0.001235/15.593653] [7629/0.006801]
  3   6 300, 0.040649 [0.002497/15.577832] [7679/0.006801]
  3   6 350, 0.047371 [0.001883/15.562127] [7729/0.006801]
Epoch 6 done. Evaluation:
(49997, 50000)
(8787, 10000)
  3   7  50, 0.006921 [0.009023/15.533709] [7820/0.006801]
  3   7 100, 0.013528 [0.001228/15.518036] [7870/0.006801]
  3   7 150, 0.020043 [0.005543/15.502339] [7920/0.006801]
  3   7 200, 0.026519 [0.001232/15.486653] [7970/0.006801]
  3   7 250, 0.033140 [0.000710/15.471037] [8020/0.006801]
  3   7 300, 0.040369 [0.002313/15.455687] [8070/0.006801]
  3   7 350, 0.047284 [0.001470/15.440228] [8120/0.006801]
Epoch 7 done. Evaluation:
(49996, 50000)
(8801, 10000)
  3   8  50, 0.006369 [0.004825/15.411840] [   0/0.006369]
  3   8 100, 0.012684 [0.002425/15.396235] [  50/0.006369]
  3   8 150, 0.019229 [0.005890/15.380719] [ 100/0.006369]
  3   8 200, 0.026088 [0.002171/15.365356] [ 150/0.006369]
  3   8 250, 0.032678 [0.001153/15.349920] [ 200/0.006369]
  3   8 300, 0.039119 [0.004592/15.334459] [ 250/0.006369]
  3   8 350, 0.045540 [0.008550/15.319017] [ 300/0.006369]
Epoch 8 done. Evaluation:
(49999, 50000)
(8791, 10000)
  3   9  50, 0.006471 [0.007192/15.291054] [ 391/0.006369]
  3   9 100, 0.013150 [0.002562/15.275770] [ 441/0.006369]
  3   9 150, 0.019585 [0.004023/15.260439] [ 491/0.006369]
  3   9 200, 0.026131 [0.000696/15.245133] [ 541/0.006369]
  3   9 250, 0.032477 [0.001347/15.229795] [ 591/0.006369]
  3   9 300, 0.038892 [0.006282/15.214508] [ 641/0.006369]
  3   9 350, 0.045154 [0.001830/15.199184] [ 691/0.006369]
Epoch 9 done. Evaluation:
(49999, 50000)
(8813, 10000)
  3  10  50, 0.006468 [0.001033/15.171498] [ 782/0.006369]
  3  10 100, 0.012815 [0.001680/15.156274] [ 832/0.006369]
  3  10 150, 0.019300 [0.003318/15.141127] [ 882/0.006369]
  3  10 200, 0.025671 [0.002193/15.125963] [ 932/0.006369]
  3  10 250, 0.032212 [0.001165/15.110902] [ 982/0.006369]
  3  10 300, 0.038638 [0.001410/15.095813] [1032/0.006369]
  3  10 350, 0.044970 [0.001284/15.080699] [1082/0.006369]
Epoch 10 done. Evaluation:
(50000, 50000)
(8804, 10000)
  3  11  50, 0.006278 [0.000757/15.053279] [   0/0.006278]
  3  11 100, 0.012631 [0.005551/15.038252] [  50/0.006278]
  3  11 150, 0.019348 [0.004629/15.023403] [ 100/0.006278]
  3  11 200, 0.025817 [0.000831/15.008469] [ 150/0.006278]
  3  11 250, 0.032120 [0.000988/14.993483] [ 200/0.006278]
  3  11 300, 0.038726 [0.002775/14.978661] [ 250/0.006278]
  3  11 350, 0.045136 [0.000961/14.963774] [ 300/0.006278]
Epoch 11 done. Evaluation:
(50000, 50000)
(8818, 10000)
  3  12  50, 0.006368 [0.000553/14.936719] [ 391/0.006278]
  3  12 100, 0.012602 [0.000676/14.921821] [ 441/0.006278]
  3  12 150, 0.018823 [0.002186/14.906948] [ 491/0.006278]
  3  12 200, 0.025231 [0.002154/14.892165] [ 541/0.006278]
  3  12 250, 0.031611 [0.000926/14.877397] [ 591/0.006278]
  3  12 300, 0.037771 [0.001437/14.862561] [ 641/0.006278]
  3  12 350, 0.043948 [0.000695/14.847748] [ 691/0.006278]
Epoch 12 done. Evaluation:
(50000, 50000)
(8800, 10000)
  3  13  50, 0.006418 [0.001334/14.821108] [ 782/0.006278]
  3  13 100, 0.012907 [0.000562/14.806507] [ 832/0.006278]
  3  13 150, 0.019175 [0.001254/14.791828] [ 882/0.006278]
  3  13 200, 0.025458 [0.002113/14.777182] [ 932/0.006278]
  3  13 250, 0.031789 [0.000808/14.762576] [ 982/0.006278]
  3  13 300, 0.038326 [0.001167/14.748091] [1032/0.006278]
  3  13 350, 0.044605 [0.001545/14.733511] [1082/0.006278]
Epoch 13 done. Evaluation:
(50000, 50000)
(8803, 10000)
  3  14  50, 0.006470 [0.002777/14.707171] [1173/0.006278]
  3  14 100, 0.012800 [0.001778/14.692665] [1223/0.006278]
  3  14 150, 0.019236 [0.002210/14.678240] [1273/0.006278]
  3  14 200, 0.025828 [0.000638/14.663915] [1323/0.006278]
  3  14 250, 0.032372 [0.000942/14.649570] [1373/0.006278]
  3  14 300, 0.039039 [0.003801/14.635320] [1423/0.006278]
  3  14 350, 0.045677 [0.001234/14.621076] [1473/0.006278]
Epoch 14 done. Evaluation:
(49999, 50000)
(8821, 10000)
  3  15  50, 0.006442 [0.001098/14.595132] [1564/0.006278]
  3  15 100, 0.013163 [0.003691/14.580989] [1614/0.006278]
  3  15 150, 0.019773 [0.003429/14.566825] [1664/0.006278]
  3  15 200, 0.026189 [0.002334/14.552597] [1714/0.006278]
  3  15 250, 0.032880 [0.002473/14.538498] [1764/0.006278]
  3  15 300, 0.039401 [0.001016/14.524362] [1814/0.006278]
  3  15 350, 0.045859 [0.001109/14.510216] [1864/0.006278]
Epoch 15 done. Evaluation:
(50000, 50000)
(8817, 10000)
  3  16  50, 0.006829 [0.001530/14.484768] [1955/0.006278]
  3  16 100, 0.013523 [0.001577/14.470770] [2005/0.006278]
  3  16 150, 0.020070 [0.001058/14.456746] [2055/0.006278]
  3  16 200, 0.026695 [0.001017/14.442785] [2105/0.006278]
  3  16 250, 0.033346 [0.000707/14.428834] [2155/0.006278]
  3  16 300, 0.039782 [0.002492/14.414825] [2205/0.006278]
  3  16 350, 0.046360 [0.003168/14.400897] [2255/0.006278]
Epoch 16 done. Evaluation:
(50000, 50000)
(8813, 10000)
  3  17  50, 0.006581 [0.000976/14.375620] [2346/0.006278]
  3  17 100, 0.012893 [0.000962/14.361649] [2396/0.006278]
  3  17 150, 0.019386 [0.001739/14.347785] [2446/0.006278]
  3  17 200, 0.025829 [0.001216/14.333915] [2496/0.006278]
  3  17 250, 0.032705 [0.005045/14.320252] [2546/0.006278]
  3  17 300, 0.039506 [0.004057/14.306587] [2596/0.006278]
  3  17 350, 0.046172 [0.000824/14.292878] [2646/0.006278]
Epoch 17 done. Evaluation:
(50000, 50000)
(8807, 10000)
  3  18  50, 0.006772 [0.002017/14.268037] [2737/0.006278]
  3  18 100, 0.013502 [0.001172/14.254400] [2787/0.006278]
  3  18 150, 0.020230 [0.003949/14.240804] [2837/0.006278]
  3  18 200, 0.026674 [0.000932/14.227101] [2887/0.006278]
  3  18 250, 0.033210 [0.000698/14.213459] [2937/0.006278]
  3  18 300, 0.039769 [0.001965/14.199857] [2987/0.006278]
  3  18 350, 0.046510 [0.001562/14.186359] [3037/0.006278]
Epoch 18 done. Evaluation:
(50000, 50000)
(8821, 10000)
  3  19  50, 0.006608 [0.000842/14.161721] [3128/0.006278]
  3  19 100, 0.013506 [0.003860/14.148343] [3178/0.006278]
  3  19 150, 0.020239 [0.000729/14.134915] [3228/0.006278]
  3  19 200, 0.026817 [0.002151/14.121443] [3278/0.006278]
  3  19 250, 0.033545 [0.000551/14.108060] [3328/0.006278]
  3  19 300, 0.040383 [0.001523/14.094745] [3378/0.006278]
  3  19 350, 0.047058 [0.001842/14.081382] [3428/0.006278]
Epoch 19 done. Evaluation:
(50000, 50000)
(8811, 10000)
  4   0  50, 0.006651 [0.001922/14.063721] [3519/0.006278]
  4   0 100, 0.013392 [0.000523/14.057076] [3569/0.006278]
  4   0 150, 0.020031 [0.000814/14.050414] [3619/0.006278]
  4   0 200, 0.026711 [0.000715/14.043765] [3669/0.006278]
  4   0 250, 0.033374 [0.001894/14.037117] [3719/0.006278]
  4   0 300, 0.039949 [0.000767/14.030454] [3769/0.006278]
  4   0 350, 0.046557 [0.000508/14.023804] [3819/0.006278]
Epoch 0 done. Evaluation:
(50000, 50000)
(8817, 10000)
  4   1  50, 0.006773 [0.000859/14.011772] [3910/0.006278]
  4   1 100, 0.013351 [0.000461/14.005128] [3960/0.006278]
  4   1 150, 0.019913 [0.000360/13.998493] [4010/0.006278]
  4   1 200, 0.026342 [0.000687/13.991828] [4060/0.006278]
  4   1 250, 0.033100 [0.001875/13.985242] [4110/0.006278]
  4   1 300, 0.039671 [0.000789/13.978621] [4160/0.006278]
  4   1 350, 0.046280 [0.000433/13.972014] [4210/0.006278]
Epoch 1 done. Evaluation:
(50000, 50000)
(8822, 10000)
  4   2  50, 0.006637 [0.000468/13.960056] [4301/0.006278]
  4   2 100, 0.013306 [0.000998/13.953477] [4351/0.006278]
  4   2 150, 0.019972 [0.000585/13.946897] [4401/0.006278]
  4   2 200, 0.026766 [0.000531/13.940356] [4451/0.006278]
  4   2 250, 0.033306 [0.000408/13.933764] [4501/0.006278]
  4   2 300, 0.040004 [0.000812/13.927209] [4551/0.006278]
  4   2 350, 0.047029 [0.000375/13.920732] [4601/0.006278]
Epoch 2 done. Evaluation:
(50000, 50000)
(8821, 10000)
  4   3  50, 0.006668 [0.000507/13.908811] [4692/0.006278]
  4   3 100, 0.013244 [0.000728/13.902251] [4742/0.006278]
  4   3 150, 0.019943 [0.000465/13.895727] [4792/0.006278]
  4   3 200, 0.026610 [0.001115/13.889193] [4842/0.006278]
  4   3 250, 0.033068 [0.000466/13.882621] [4892/0.006278]
  4   3 300, 0.039742 [0.001829/13.876105] [4942/0.006278]
  4   3 350, 0.046501 [0.000602/13.869613] [4992/0.006278]
Epoch 3 done. Evaluation:
(50000, 50000)
(8817, 10000)
  4   4  50, 0.006709 [0.000408/13.857782] [5083/0.006278]
  4   4 100, 0.013402 [0.000524/13.851294] [5133/0.006278]
  4   4 150, 0.019943 [0.000562/13.844770] [5183/0.006278]
  4   4 200, 0.026820 [0.001996/13.838315] [5233/0.006278]
  4   4 250, 0.033550 [0.000705/13.831849] [5283/0.006278]
  4   4 300, 0.040470 [0.001061/13.825429] [5333/0.006278]
  4   4 350, 0.047196 [0.000905/13.818971] [5383/0.006278]
Epoch 4 done. Evaluation:
(50000, 50000)
(8822, 10000)
  4   5  50, 0.006687 [0.000485/13.807225] [5474/0.006278]
  4   5 100, 0.013374 [0.000437/13.800778] [5524/0.006278]
  4   5 150, 0.020163 [0.000356/13.794356] [5574/0.006278]
  4   5 200, 0.026831 [0.000853/13.787915] [5624/0.006278]
  4   5 250, 0.033507 [0.000529/13.781479] [5674/0.006278]
  4   5 300, 0.040413 [0.001321/13.775097] [5724/0.006278]
  4   5 350, 0.047175 [0.000390/13.768681] [5774/0.006278]
Epoch 5 done. Evaluation:
(50000, 50000)
(8817, 10000)
  4   6  50, 0.006702 [0.000523/13.757002] [5865/0.006278]
  4   6 100, 0.013329 [0.000401/13.750579] [5915/0.006278]
  4   6 150, 0.020050 [0.000319/13.744184] [5965/0.006278]
  4   6 200, 0.026866 [0.000722/13.737815] [6015/0.006278]
  4   6 250, 0.033431 [0.000569/13.731387] [6065/0.006278]
  4   6 300, 0.040085 [0.000517/13.724985] [6115/0.006278]
  4   6 350, 0.046682 [0.000506/13.718577] [6165/0.006278]
Epoch 6 done. Evaluation:
(50000, 50000)
(8824, 10000)
  4   7  50, 0.006699 [0.000741/13.706997] [6256/0.006278]
  4   7 100, 0.013286 [0.000534/13.700599] [6306/0.006278]
  4   7 150, 0.020159 [0.000496/13.694272] [6356/0.006278]
  4   7 200, 0.026965 [0.000331/13.687940] [6406/0.006278]
  4   7 250, 0.033906 [0.000482/13.681645] [6456/0.006278]
  4   7 300, 0.040782 [0.000378/13.675342] [6506/0.006278]
  4   7 350, 0.047354 [0.000572/13.668970] [6556/0.006278]
Epoch 7 done. Evaluation:
(50000, 50000)
(8822, 10000)
  4   8  50, 0.006715 [0.000676/13.657458] [6647/0.006278]
  4   8 100, 0.013409 [0.000736/13.651128] [6697/0.006278]
  4   8 150, 0.019983 [0.000758/13.644776] [6747/0.006278]
  4   8 200, 0.026764 [0.000886/13.638474] [6797/0.006278]
  4   8 250, 0.033500 [0.000312/13.632171] [6847/0.006278]
  4   8 300, 0.040300 [0.000761/13.625886] [6897/0.006278]
  4   8 350, 0.047239 [0.000473/13.619641] [6947/0.006278]
Epoch 8 done. Evaluation:
(50000, 50000)
(8821, 10000)
  4   9  50, 0.006802 [0.000598/13.608218] [7038/0.006278]
  4   9 100, 0.013449 [0.000588/13.601914] [7088/0.006278]
  4   9 150, 0.020356 [0.001081/13.595677] [7138/0.006278]
  4   9 200, 0.027009 [0.000614/13.589388] [7188/0.006278]
  4   9 250, 0.033638 [0.000345/13.583103] [7238/0.006278]
  4   9 300, 0.040174 [0.001072/13.576794] [7288/0.006278]
  4   9 350, 0.046859 [0.000370/13.570530] [7338/0.006278]
Epoch 9 done. Evaluation:
(50000, 50000)
(8824, 10000)
  4  10  50, 0.006709 [0.000421/13.559214] [7429/0.006278]
  4  10 100, 0.013530 [0.000417/13.552996] [7479/0.006278]
  4  10 150, 0.020378 [0.000366/13.546790] [7529/0.006278]
  4  10 200, 0.027528 [0.000589/13.540658] [7579/0.006278]
  4  10 250, 0.034233 [0.000365/13.534427] [7629/0.006278]
  4  10 300, 0.041041 [0.000533/13.528221] [7679/0.006278]
  4  10 350, 0.047840 [0.000740/13.522023] [7729/0.006278]
Epoch 10 done. Evaluation:
(50000, 50000)
(8820, 10000)
  4  11  50, 0.006680 [0.000387/13.510762] [7820/0.006278]
  4  11 100, 0.013498 [0.000465/13.504581] [7870/0.006278]
  4  11 150, 0.020269 [0.000638/13.498386] [7920/0.006278]
  4  11 200, 0.027096 [0.000649/13.492223] [7970/0.006278]
  4  11 250, 0.033795 [0.000281/13.486025] [8020/0.006278]
  4  11 300, 0.040568 [0.000505/13.479856] [8070/0.006278]
  4  11 350, 0.047431 [0.000521/13.473709] [8120/0.006278]
Epoch 11 done. Evaluation:
(50000, 50000)
(8824, 10000)
  4  12  50, 0.006544 [0.000498/13.462435] [8211/0.006278]
  4  12 100, 0.013344 [0.002211/13.456289] [8261/0.006278]
  4  12 150, 0.020089 [0.000322/13.450131] [8311/0.006278]
  4  12 200, 0.026879 [0.000683/13.443994] [8361/0.006278]
  4  12 250, 0.033403 [0.000342/13.437797] [8411/0.006278]
  4  12 300, 0.040239 [0.000687/13.431680] [8461/0.006278]
  4  12 350, 0.046979 [0.000489/13.425543] [8511/0.006278]
Epoch 12 done. Evaluation:
(50000, 50000)
(8820, 10000)
  4  13  50, 0.007054 [0.000714/13.414490] [8602/0.006278]
  4  13 100, 0.013911 [0.001096/13.408397] [8652/0.006278]
  4  13 150, 0.020599 [0.000624/13.402271] [8702/0.006278]
  4  13 200, 0.027495 [0.000282/13.396198] [8752/0.006278]
  4  13 250, 0.034230 [0.000371/13.390089] [8802/0.006278]
  4  13 300, 0.041087 [0.000572/13.384017] [8852/0.006278]
  4  13 350, 0.048019 [0.000393/13.377965] [8902/0.006278]
Epoch 13 done. Evaluation:
(50000, 50000)
(8830, 10000)
  4  14  50, 0.006880 [0.000712/13.366961] [8993/0.006278]
  4  14 100, 0.013918 [0.001655/13.360948] [9043/0.006278]
  4  14 150, 0.020652 [0.001210/13.354869] [9093/0.006278]
  4  14 200, 0.027656 [0.000645/13.348862] [9143/0.006278]
  4  14 250, 0.034754 [0.000652/13.342881] [9193/0.006278]
  4  14 300, 0.041948 [0.000441/13.336927] [9243/0.006278]
  4  14 350, 0.048995 [0.000345/13.330947] [9293/0.006278]
Epoch 14 done. Evaluation:
(50000, 50000)
(8825, 10000)
  4  15  50, 0.006813 [0.000426/13.319964] [9384/0.006278]
  4  15 100, 0.013501 [0.000423/13.313909] [9434/0.006278]
  4  15 150, 0.020399 [0.000692/13.307912] [9484/0.006278]
  4  15 200, 0.027190 [0.000395/13.301887] [9534/0.006278]
  4  15 250, 0.034089 [0.000829/13.295896] [9584/0.006278]
  4  15 300, 0.040973 [0.000949/13.289906] [9634/0.006278]
  4  15 350, 0.047844 [0.000837/13.283917] [9684/0.006278]
Epoch 15 done. Evaluation:
(50000, 50000)
(8818, 10000)
  4  16  50, 0.006838 [0.000648/13.272996] [9775/0.006278]
  4  16 100, 0.013758 [0.000550/13.267028] [9825/0.006278]
  4  16 150, 0.020622 [0.000410/13.261055] [9875/0.006278]
  4  16 200, 0.027561 [0.000322/13.255100] [9925/0.006278]
  4  16 250, 0.034421 [0.000337/13.249141] [9975/0.006278]
  4  16 300, 0.041054 [0.000293/13.243129] [10025/0.006278]
  4  16 350, 0.047995 [0.000735/13.237195] [10075/0.006278]
Epoch 16 done. Evaluation:
(50000, 50000)
(8820, 10000)
  4  17  50, 0.007077 [0.000377/13.226423] [10166/0.006278]
  4  17 100, 0.013937 [0.000305/13.220482] [10216/0.006278]
  4  17 150, 0.020662 [0.000333/13.214516] [10266/0.006278]
  4  17 200, 0.027548 [0.000661/13.208592] [10316/0.006278]
  4  17 250, 0.034446 [0.000637/13.202679] [10366/0.006278]
  4  17 300, 0.041225 [0.000812/13.196740] [10416/0.006278]
  4  17 350, 0.048413 [0.000827/13.190909] [10466/0.006278]
Epoch 17 done. Evaluation:
(50000, 50000)
(8834, 10000)
  4  18  50, 0.006782 [0.000753/13.180144] [10557/0.006278]
  4  18 100, 0.014089 [0.000787/13.174352] [10607/0.006278]
  4  18 150, 0.020847 [0.001218/13.168434] [10657/0.006278]
  4  18 200, 0.027525 [0.000645/13.162499] [10707/0.006278]
  4  18 250, 0.034217 [0.000331/13.156575] [10757/0.006278]
  4  18 300, 0.040933 [0.001443/13.150660] [10807/0.006278]
  4  18 350, 0.047777 [0.000584/13.144776] [10857/0.006278]
Epoch 18 done. Evaluation:
(50000, 50000)
(8832, 10000)
  4  19  50, 0.006698 [0.001257/13.134069] [10948/0.006278]
  4  19 100, 0.013370 [0.000762/13.128161] [10998/0.006278]
  4  19 150, 0.020396 [0.000323/13.122341] [11048/0.006278]
  4  19 200, 0.027085 [0.000922/13.116441] [11098/0.006278]
  4  19 250, 0.034086 [0.000525/13.110619] [11148/0.006278]
  4  19 300, 0.040732 [0.000500/13.104729] [11198/0.006278]
  4  19 350, 0.047580 [0.000450/13.098885] [11248/0.006278]
Epoch 19 done. Evaluation:
(50000, 50000)
(8816, 10000)
