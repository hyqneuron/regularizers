Sequential (
  (conv1_1): Sequential (
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (conv1_2): Sequential (
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (pool1): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
  (conv2_1): Sequential (
    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (conv2_2): Sequential (
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (pool2): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
  (conv3_1): Sequential (
    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (conv3_2): Sequential (
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (pool3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
  (conv4_1): Sequential (
    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (conv4_2): Sequential (
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (pool4): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
  (conv5_1): Sequential (
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (conv5_2): Sequential (
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (pool5): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
  (fc6): Sequential (
    (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (logit): Conv2d(256, 10, kernel_size=(1, 1), stride=(1, 1))
  (flatter): Flatten()
)
{'L1_decay': 5e-06,
 'batch_size': 128,
 'force_name': False,
 'graphfolder': 'logs/exp4_graphs/',
 'learning_rate': 0.1,
 'logfile': 'logs/exp4.log',
 'mode': '',
 'name': 'exp4',
 'num_base': 32,
 'optimizer': 'SGD',
 'weight_decay': 0.004}
Decayed training with schedule: [20, 20, 20, 20, 20]
  0   0  50, 1.831578 [0.379738/70.852146] [   0/1.831578]
  0   0 100, 3.330197 [0.342181/69.489329] [  50/1.831578]
  0   0 150, 4.707105 [0.341329/68.152733] [ 100/1.831578]
  0   0 200, 5.981955 [0.369016/66.846406] [ 150/1.831578]
  0   0 250, 7.181574 [0.345799/65.566616] [ 200/1.831578]
  0   0 300, 8.328272 [0.318737/64.311157] [ 250/1.831578]
  0   0 350, 9.392699 [0.287271/63.083904] [ 300/1.831578]
Epoch 0 done. Evaluation:
(26291, 50000)
(5087, 10000)
  0   1  50, 0.974049 [0.349323/60.913788] [   0/0.974049]
  0   1 100, 1.882572 [0.323868/59.758984] [  50/0.974049]
  0   1 150, 2.788366 [0.323291/58.625481] [ 100/0.974049]
  0   1 200, 3.680130 [0.325245/57.514349] [ 150/0.974049]
  0   1 250, 4.538228 [0.296156/56.423626] [ 200/0.974049]
  0   1 300, 5.385109 [0.306327/55.356924] [ 250/0.974049]
  0   1 350, 6.209552 [0.351946/54.311334] [ 300/0.974049]
Epoch 1 done. Evaluation:
(34427, 50000)
(7082, 10000)
  0   2  50, 0.733837 [0.356487/52.472602] [   0/0.733837]
  0   2 100, 1.467522 [0.362813/51.494028] [  50/0.733837]
  0   2 150, 2.171818 [0.338002/50.537215] [ 100/0.733837]
  0   2 200, 2.910492 [0.334140/49.598674] [ 150/0.733837]
  0   2 250, 3.600773 [0.288620/48.677507] [ 200/0.733837]
  0   2 300, 4.290572 [0.324337/47.774356] [ 250/0.733837]
  0   2 350, 4.977152 [0.295458/46.890975] [ 300/0.733837]
Epoch 2 done. Evaluation:
(37696, 50000)
(6887, 10000)
  0   3  50, 0.607763 [0.327159/45.338220] [   0/0.607763]
  0   3 100, 1.210221 [0.310928/44.512715] [  50/0.607763]
  0   3 150, 1.823110 [0.371914/43.706324] [ 100/0.607763]
  0   3 200, 2.438291 [0.340052/42.918691] [ 150/0.607763]
  0   3 250, 3.068175 [0.311607/42.142435] [ 200/0.607763]
  0   3 300, 3.684341 [0.257252/41.385446] [ 250/0.607763]
  0   3 350, 4.293736 [0.296386/40.643357] [ 300/0.607763]
Epoch 3 done. Evaluation:
(39479, 50000)
(7172, 10000)
  0   4  50, 0.549273 [0.316229/39.347339] [   0/0.549273]
  0   4 100, 1.074997 [0.325658/38.658965] [  50/0.549273]
  0   4 150, 1.649772 [0.350311/37.983331] [ 100/0.549273]
  0   4 200, 2.190669 [0.295654/37.327085] [ 150/0.549273]
  0   4 250, 2.757873 [0.332081/36.680443] [ 200/0.549273]
  0   4 300, 3.303015 [0.300955/36.047833] [ 250/0.549273]
  0   4 350, 3.854957 [0.391536/35.430876] [ 300/0.549273]
Epoch 4 done. Evaluation:
(40495, 50000)
(7156, 10000)
  0   5  50, 0.467411 [0.335399/34.347487] [   0/0.467411]
  0   5 100, 0.945397 [0.363952/33.773299] [  50/0.467411]
  0   5 150, 1.466824 [0.325940/33.213348] [ 100/0.467411]
  0   5 200, 1.988642 [0.316008/32.670569] [ 150/0.467411]
  0   5 250, 2.489328 [0.313628/32.134412] [ 200/0.467411]
  0   5 300, 2.995312 [0.330140/31.612178] [ 250/0.467411]
  0   5 350, 3.528585 [0.316188/31.104021] [ 300/0.467411]
Epoch 5 done. Evaluation:
(41415, 50000)
(7078, 10000)
  0   6  50, 0.442341 [0.370591/30.212733] [   0/0.442341]
  0   6 100, 0.913677 [0.344887/29.737309] [  50/0.442341]
  0   6 150, 1.385220 [0.393231/29.284041] [ 100/0.442341]
  0   6 200, 1.854616 [0.328275/28.837237] [ 150/0.442341]
  0   6 250, 2.329506 [0.364822/28.396960] [ 200/0.442341]
  0   6 300, 2.813228 [0.390250/27.964385] [ 250/0.442341]
  0   6 350, 3.301114 [0.352954/27.548504] [ 300/0.442341]
Epoch 6 done. Evaluation:
(41911, 50000)
(7217, 10000)
  0   7  50, 0.436461 [0.387153/26.824998] [   0/0.436461]
  0   7 100, 0.875521 [0.313031/26.438189] [  50/0.436461]
  0   7 150, 1.298429 [0.483800/26.065220] [ 100/0.436461]
  0   7 200, 1.755393 [0.329445/25.700239] [ 150/0.436461]
  0   7 250, 2.205500 [0.353417/25.344435] [ 200/0.436461]
  0   7 300, 2.668244 [0.361190/24.998068] [ 250/0.436461]
  0   7 350, 3.126277 [0.359793/24.664565] [ 300/0.436461]
Epoch 7 done. Evaluation:
(42512, 50000)
(7716, 10000)
  0   8  50, 0.398563 [0.360818/24.068536] [   0/0.398563]
  0   8 100, 0.828422 [0.413133/23.768823] [  50/0.398563]
  0   8 150, 1.264991 [0.376757/23.474092] [ 100/0.398563]
  0   8 200, 1.708017 [0.284810/23.187976] [ 150/0.398563]
  0   8 250, 2.151440 [0.366386/22.900869] [ 200/0.398563]
  0   8 300, 2.565446 [0.375239/22.622964] [ 250/0.398563]
  0   8 350, 3.002243 [0.308902/22.358366] [ 300/0.398563]
Epoch 8 done. Evaluation:
(42756, 50000)
(7397, 10000)
  0   9  50, 0.380414 [0.354769/21.896327] [   0/0.380414]
  0   9 100, 0.769287 [0.344427/21.658395] [  50/0.380414]
  0   9 150, 1.184417 [0.406848/21.428078] [ 100/0.380414]
  0   9 200, 1.573836 [0.391662/21.204478] [ 150/0.380414]
  0   9 250, 1.998066 [0.321053/20.996740] [ 200/0.380414]
  0   9 300, 2.431303 [0.407082/20.785492] [ 250/0.380414]
  0   9 350, 2.875066 [0.398415/20.581343] [ 300/0.380414]
Epoch 9 done. Evaluation:
(43182, 50000)
(6853, 10000)
  0  10  50, 0.346954 [0.414603/20.225747] [   0/0.346954]
  0  10 100, 0.732501 [0.416193/20.052691] [  50/0.346954]
  0  10 150, 1.120650 [0.488371/19.882385] [ 100/0.346954]
  0  10 200, 1.521968 [0.323821/19.709969] [ 150/0.346954]
  0  10 250, 1.941436 [0.365898/19.545736] [ 200/0.346954]
  0  10 300, 2.361475 [0.389546/19.380129] [ 250/0.346954]
  0  10 350, 2.794922 [0.376521/19.229541] [ 300/0.346954]
Epoch 10 done. Evaluation:
(43370, 50000)
(7316, 10000)
  0  11  50, 0.361801 [0.351923/18.963110] [ 391/0.346954]
  0  11 100, 0.735384 [0.425069/18.836440] [ 441/0.346954]
  0  11 150, 1.134179 [0.348317/18.704322] [ 491/0.346954]
  0  11 200, 1.539449 [0.321815/18.590032] [ 541/0.346954]
  0  11 250, 1.938858 [0.409776/18.470453] [ 591/0.346954]
  0  11 300, 2.342536 [0.381699/18.360661] [ 641/0.346954]
  0  11 350, 2.745093 [0.439674/18.249727] [ 691/0.346954]
Epoch 11 done. Evaluation:
(43454, 50000)
(6440, 10000)
  0  12  50, 0.352258 [0.390581/18.056093] [ 782/0.346954]
  0  12 100, 0.715597 [0.495598/17.962848] [ 832/0.346954]
  0  12 150, 1.098062 [0.372632/17.872357] [ 882/0.346954]
  0  12 200, 1.488616 [0.509747/17.785524] [ 932/0.346954]
  0  12 250, 1.861074 [0.326477/17.700958] [ 982/0.346954]
  0  12 300, 2.255000 [0.405978/17.611009] [1032/0.346954]
  0  12 350, 2.675650 [0.321071/17.541340] [1082/0.346954]
Epoch 12 done. Evaluation:
(43606, 50000)
(5624, 10000)
  0  13  50, 0.335977 [0.331004/17.391677] [   0/0.335977]
  0  13 100, 0.696416 [0.408608/17.320764] [  50/0.335977]
  0  13 150, 1.091973 [0.456645/17.262338] [ 100/0.335977]
  0  13 200, 1.468512 [0.436851/17.211046] [ 150/0.335977]
  0  13 250, 1.878740 [0.452212/17.157543] [ 200/0.335977]
  0  13 300, 2.257761 [0.366154/17.087292] [ 250/0.335977]
  0  13 350, 2.656678 [0.382296/17.037521] [ 300/0.335977]
Epoch 13 done. Evaluation:
(43820, 50000)
(7247, 10000)
  0  14  50, 0.328994 [0.348347/16.917444] [   0/0.328994]
  0  14 100, 0.693971 [0.446873/16.882651] [  50/0.328994]
  0  14 150, 1.054821 [0.435574/16.842924] [ 100/0.328994]
  0  14 200, 1.439043 [0.395236/16.819991] [ 150/0.328994]
  0  14 250, 1.826025 [0.409442/16.773471] [ 200/0.328994]
  0  14 300, 2.219183 [0.331634/16.728697] [ 250/0.328994]
  0  14 350, 2.593590 [0.344073/16.686197] [ 300/0.328994]
Epoch 14 done. Evaluation:
(43809, 50000)
(7592, 10000)
  0  15  50, 0.331645 [0.388714/16.615834] [ 391/0.328994]
  0  15 100, 0.675504 [0.394666/16.590205] [ 441/0.328994]
  0  15 150, 1.024416 [0.398259/16.563372] [ 491/0.328994]
  0  15 200, 1.388687 [0.513144/16.541160] [ 541/0.328994]
  0  15 250, 1.761781 [0.422623/16.522033] [ 591/0.328994]
  0  15 300, 2.121128 [0.341835/16.492391] [ 641/0.328994]
  0  15 350, 2.501778 [0.362013/16.476472] [ 691/0.328994]
Epoch 15 done. Evaluation:
(44056, 50000)
(7682, 10000)
  0  16  50, 0.325295 [0.378633/16.437210] [   0/0.325295]
  0  16 100, 0.668956 [0.365711/16.425584] [  50/0.325295]
  0  16 150, 1.023190 [0.380301/16.398484] [ 100/0.325295]
  0  16 200, 1.385670 [0.388976/16.369574] [ 150/0.325295]
  0  16 250, 1.764787 [0.425497/16.339732] [ 200/0.325295]
  0  16 300, 2.119535 [0.339231/16.314823] [ 250/0.325295]
  0  16 350, 2.496265 [0.458398/16.294998] [ 300/0.325295]
Epoch 16 done. Evaluation:
(44129, 50000)
(7148, 10000)
  0  17  50, 0.323640 [0.455514/16.274833] [   0/0.323640]
  0  17 100, 0.667390 [0.354028/16.284202] [  50/0.323640]
  0  17 150, 1.017395 [0.356890/16.280400] [ 100/0.323640]
  0  17 200, 1.368720 [0.431427/16.267327] [ 150/0.323640]
  0  17 250, 1.745677 [0.351057/16.254166] [ 200/0.323640]
  0  17 300, 2.098334 [0.427201/16.237624] [ 250/0.323640]
  0  17 350, 2.459303 [0.435988/16.212728] [ 300/0.323640]
Epoch 17 done. Evaluation:
(44155, 50000)
(7864, 10000)
  0  18  50, 0.306857 [0.428357/16.165335] [   0/0.306857]
  0  18 100, 0.634228 [0.422466/16.176394] [  50/0.306857]
  0  18 150, 0.992810 [0.411084/16.195816] [ 100/0.306857]
  0  18 200, 1.354941 [0.514558/16.201698] [ 150/0.306857]
  0  18 250, 1.728541 [0.517546/16.195725] [ 200/0.306857]
  0  18 300, 2.087334 [0.364045/16.179910] [ 250/0.306857]
  0  18 350, 2.448360 [0.390520/16.178680] [ 300/0.306857]
Epoch 18 done. Evaluation:
(44141, 50000)
(7113, 10000)
  0  19  50, 0.298336 [0.434274/16.162170] [   0/0.298336]
  0  19 100, 0.635795 [0.410984/16.165894] [  50/0.298336]
  0  19 150, 0.952348 [0.511975/16.162895] [ 100/0.298336]
  0  19 200, 1.287650 [0.408555/16.145248] [ 150/0.298336]
  0  19 250, 1.637980 [0.363724/16.127817] [ 200/0.298336]
  0  19 300, 1.989291 [0.419913/16.124703] [ 250/0.298336]
  0  19 350, 2.351346 [0.456632/16.115983] [ 300/0.298336]
Epoch 19 done. Evaluation:
(44428, 50000)
(7388, 10000)
  1   0  50, 0.224148 [0.177576/16.048324] [   0/0.224148]
  1   0 100, 0.422260 [0.140112/15.969395] [  50/0.224148]
  1   0 150, 0.623171 [0.149984/15.899858] [ 100/0.224148]
  1   0 200, 0.819947 [0.183579/15.827042] [ 150/0.224148]
  1   0 250, 1.015818 [0.219808/15.763684] [ 200/0.224148]
  1   0 300, 1.222869 [0.159927/15.703717] [ 250/0.224148]
  1   0 350, 1.425847 [0.225436/15.643666] [ 300/0.224148]
Epoch 0 done. Evaluation:
(46880, 50000)
(8508, 10000)
  1   1  50, 0.154489 [0.246531/15.547004] [   0/0.154489]
  1   1 100, 0.312500 [0.236724/15.490707] [  50/0.154489]
  1   1 150, 0.494712 [0.280530/15.446057] [ 100/0.154489]
  1   1 200, 0.682287 [0.189041/15.411288] [ 150/0.154489]
  1   1 250, 0.857925 [0.208345/15.364948] [ 200/0.154489]
  1   1 300, 1.061909 [0.242955/15.330840] [ 250/0.154489]
  1   1 350, 1.267910 [0.188618/15.300037] [ 300/0.154489]
Epoch 1 done. Evaluation:
(47130, 50000)
(8404, 10000)
  1   2  50, 0.163918 [0.179131/15.227068] [ 391/0.154489]
  1   2 100, 0.323488 [0.267748/15.188012] [ 441/0.154489]
  1   2 150, 0.499607 [0.150580/15.159406] [ 491/0.154489]
  1   2 200, 0.674240 [0.163235/15.124678] [ 541/0.154489]
  1   2 250, 0.860983 [0.229594/15.102661] [ 591/0.154489]
  1   2 300, 1.070921 [0.247288/15.087392] [ 641/0.154489]
  1   2 350, 1.269757 [0.233991/15.073263] [ 691/0.154489]
Epoch 2 done. Evaluation:
(47108, 50000)
(8253, 10000)
  1   3  50, 0.166661 [0.265378/15.032067] [ 782/0.154489]
  1   3 100, 0.341045 [0.200736/15.020623] [ 832/0.154489]
  1   3 150, 0.529449 [0.277836/15.007061] [ 882/0.154489]
  1   3 200, 0.717472 [0.345479/14.998761] [ 932/0.154489]
  1   3 250, 0.916426 [0.255097/14.990323] [ 982/0.154489]
  1   3 300, 1.130810 [0.211787/14.985220] [1032/0.154489]
  1   3 350, 1.344676 [0.157015/14.976786] [1082/0.154489]
Epoch 3 done. Evaluation:
(46871, 50000)
(7815, 10000)
  1   4  50, 0.162276 [0.262969/14.957391] [1173/0.154489]
  1   4 100, 0.341570 [0.291922/14.943496] [1223/0.154489]
  1   4 150, 0.548500 [0.248959/14.945792] [1273/0.154489]
  1   4 200, 0.750364 [0.321488/14.943194] [1323/0.154489]
  1   4 250, 0.952923 [0.336774/14.939912] [1373/0.154489]
  1   4 300, 1.174894 [0.280600/14.948673] [1423/0.154489]
  1   4 350, 1.366580 [0.291711/14.943662] [1473/0.154489]
Epoch 4 done. Evaluation:
(46865, 50000)
(7665, 10000)
  1   5  50, 0.185203 [0.261366/14.935346] [1564/0.154489]
  1   5 100, 0.361422 [0.234902/14.925423] [1614/0.154489]
  1   5 150, 0.558444 [0.305483/14.934269] [1664/0.154489]
  1   5 200, 0.744136 [0.184387/14.929734] [1714/0.154489]
  1   5 250, 0.972942 [0.196170/14.942459] [1764/0.154489]
  1   5 300, 1.195623 [0.277548/14.941515] [1814/0.154489]
  1   5 350, 1.392330 [0.209109/14.936220] [1864/0.154489]
Epoch 5 done. Evaluation:
(46845, 50000)
(8178, 10000)
  1   6  50, 0.169406 [0.180474/14.931730] [1955/0.154489]
  1   6 100, 0.346203 [0.340101/14.926345] [2005/0.154489]
  1   6 150, 0.557317 [0.255981/14.935452] [2055/0.154489]
  1   6 200, 0.749013 [0.225693/14.936465] [2105/0.154489]
  1   6 250, 0.960270 [0.269966/14.946037] [2155/0.154489]
  1   6 300, 1.169523 [0.262462/14.946435] [2205/0.154489]
  1   6 350, 1.387447 [0.284648/14.947509] [2255/0.154489]
Epoch 6 done. Evaluation:
(46837, 50000)
(7680, 10000)
  1   7  50, 0.168236 [0.292266/14.943007] [2346/0.154489]
  1   7 100, 0.342137 [0.383449/14.944808] [2396/0.154489]
  1   7 150, 0.526763 [0.228992/14.950546] [2446/0.154489]
  1   7 200, 0.717171 [0.293872/14.948559] [2496/0.154489]
  1   7 250, 0.913864 [0.289598/14.950291] [2546/0.154489]
  1   7 300, 1.116850 [0.209454/14.953762] [2596/0.154489]
  1   7 350, 1.339028 [0.232740/14.962797] [2646/0.154489]
Epoch 7 done. Evaluation:
(46897, 50000)
(7879, 10000)
  1   8  50, 0.175435 [0.285644/14.984947] [2737/0.154489]
  1   8 100, 0.386713 [0.214478/15.000799] [2787/0.154489]
  1   8 150, 0.568251 [0.321449/15.002448] [2837/0.154489]
  1   8 200, 0.763466 [0.330621/15.010174] [2887/0.154489]
  1   8 250, 0.953098 [0.227429/15.007428] [2937/0.154489]
  1   8 300, 1.166481 [0.297860/15.011848] [2987/0.154489]
  1   8 350, 1.381217 [0.283659/15.015999] [3037/0.154489]
Epoch 8 done. Evaluation:
(46780, 50000)
(8156, 10000)
  1   9  50, 0.167170 [0.350111/15.015771] [3128/0.154489]
  1   9 100, 0.345108 [0.241469/15.014348] [3178/0.154489]
  1   9 150, 0.537168 [0.290354/15.031503] [3228/0.154489]
  1   9 200, 0.745749 [0.305533/15.045309] [3278/0.154489]
  1   9 250, 0.941041 [0.304490/15.054612] [3328/0.154489]
  1   9 300, 1.141893 [0.252196/15.058853] [3378/0.154489]
  1   9 350, 1.358291 [0.312299/15.067149] [3428/0.154489]
Epoch 9 done. Evaluation:
(46863, 50000)
(7757, 10000)
  1  10  50, 0.168980 [0.258657/15.066318] [3519/0.154489]
  1  10 100, 0.352624 [0.224932/15.066631] [3569/0.154489]
  1  10 150, 0.554474 [0.306587/15.076058] [3619/0.154489]
  1  10 200, 0.741158 [0.181723/15.077421] [3669/0.154489]
  1  10 250, 0.940278 [0.282382/15.098501] [3719/0.154489]
  1  10 300, 1.158167 [0.299783/15.116375] [3769/0.154489]
  1  10 350, 1.370286 [0.305399/15.126650] [3819/0.154489]
Epoch 10 done. Evaluation:
(46805, 50000)
(7910, 10000)
  1  11  50, 0.176503 [0.188895/15.123462] [3910/0.154489]
  1  11 100, 0.345853 [0.266060/15.114308] [3960/0.154489]
  1  11 150, 0.523074 [0.272902/15.112749] [4010/0.154489]
  1  11 200, 0.697178 [0.277455/15.113894] [4060/0.154489]
  1  11 250, 0.882847 [0.320483/15.112495] [4110/0.154489]
  1  11 300, 1.106450 [0.214318/15.127362] [4160/0.154489]
  1  11 350, 1.307428 [0.367147/15.139781] [4210/0.154489]
Epoch 11 done. Evaluation:
(46940, 50000)
(7478, 10000)
  1  12  50, 0.163898 [0.282022/15.137789] [4301/0.154489]
  1  12 100, 0.340327 [0.320063/15.133505] [4351/0.154489]
  1  12 150, 0.522335 [0.156517/15.133385] [4401/0.154489]
  1  12 200, 0.714766 [0.264276/15.144218] [4451/0.154489]
  1  12 250, 0.900412 [0.280762/15.144434] [4501/0.154489]
  1  12 300, 1.103976 [0.277555/15.154140] [4551/0.154489]
  1  12 350, 1.311651 [0.306301/15.164988] [4601/0.154489]
Epoch 12 done. Evaluation:
(46989, 50000)
(7699, 10000)
  1  13  50, 0.168190 [0.246942/15.160425] [4692/0.154489]
  1  13 100, 0.328225 [0.286544/15.149575] [4742/0.154489]
  1  13 150, 0.507138 [0.257628/15.158293] [4792/0.154489]
  1  13 200, 0.699459 [0.338950/15.170907] [4842/0.154489]
  1  13 250, 0.893079 [0.301903/15.175514] [4892/0.154489]
  1  13 300, 1.093911 [0.226200/15.184429] [4942/0.154489]
  1  13 350, 1.285690 [0.305358/15.185245] [4992/0.154489]
Epoch 13 done. Evaluation:
(47078, 50000)
(7187, 10000)
  1  14  50, 0.156058 [0.249526/15.172641] [5083/0.154489]
  1  14 100, 0.320510 [0.267657/15.167245] [5133/0.154489]
  1  14 150, 0.489103 [0.270834/15.158017] [5183/0.154489]
  1  14 200, 0.670892 [0.279632/15.164127] [5233/0.154489]
  1  14 250, 0.869940 [0.316305/15.166491] [5283/0.154489]
  1  14 300, 1.075802 [0.243220/15.170338] [5333/0.154489]
  1  14 350, 1.274050 [0.307551/15.183874] [5383/0.154489]
Epoch 14 done. Evaluation:
(47114, 50000)
(7582, 10000)
  1  15  50, 0.148662 [0.312235/15.168540] [   0/0.148662]
  1  15 100, 0.312462 [0.267214/15.164743] [  50/0.148662]
  1  15 150, 0.476379 [0.239293/15.165013] [ 100/0.148662]
  1  15 200, 0.670688 [0.305342/15.178735] [ 150/0.148662]
  1  15 250, 0.863025 [0.320927/15.187381] [ 200/0.148662]
  1  15 300, 1.080909 [0.342111/15.212310] [ 250/0.148662]
  1  15 350, 1.287131 [0.299784/15.222741] [ 300/0.148662]
Epoch 15 done. Evaluation:
(47052, 50000)
(8363, 10000)
  1  16  50, 0.171238 [0.256081/15.220415] [ 391/0.148662]
  1  16 100, 0.328819 [0.267105/15.208162] [ 441/0.148662]
  1  16 150, 0.502403 [0.324051/15.211248] [ 491/0.148662]
  1  16 200, 0.677735 [0.288286/15.211175] [ 541/0.148662]
  1  16 250, 0.867567 [0.287029/15.221869] [ 591/0.148662]
  1  16 300, 1.062185 [0.294353/15.233565] [ 641/0.148662]
  1  16 350, 1.267331 [0.197166/15.251148] [ 691/0.148662]
Epoch 16 done. Evaluation:
(47102, 50000)
(8258, 10000)
  1  17  50, 0.150508 [0.224428/15.235821] [ 782/0.148662]
  1  17 100, 0.308929 [0.246654/15.239538] [ 832/0.148662]
  1  17 150, 0.495706 [0.267497/15.256987] [ 882/0.148662]
  1  17 200, 0.673434 [0.200416/15.259809] [ 932/0.148662]
  1  17 250, 0.852351 [0.375146/15.261869] [ 982/0.148662]
  1  17 300, 1.048716 [0.245123/15.263493] [1032/0.148662]
  1  17 350, 1.245007 [0.271881/15.272327] [1082/0.148662]
Epoch 17 done. Evaluation:
(47158, 50000)
(8197, 10000)
  1  18  50, 0.146969 [0.319563/15.253995] [   0/0.146969]
  1  18 100, 0.315963 [0.162338/15.259122] [  50/0.146969]
  1  18 150, 0.491888 [0.264620/15.265243] [ 100/0.146969]
  1  18 200, 0.678727 [0.314748/15.280451] [ 150/0.146969]
  1  18 250, 0.885876 [0.331794/15.290514] [ 200/0.146969]
  1  18 300, 1.093761 [0.365111/15.292683] [ 250/0.146969]
  1  18 350, 1.292479 [0.255438/15.288860] [ 300/0.146969]
Epoch 18 done. Evaluation:
(47032, 50000)
(8057, 10000)
  1  19  50, 0.153443 [0.211656/15.271432] [ 391/0.146969]
  1  19 100, 0.329968 [0.223463/15.279678] [ 441/0.146969]
  1  19 150, 0.491501 [0.250179/15.267194] [ 491/0.146969]
  1  19 200, 0.674772 [0.245060/15.271621] [ 541/0.146969]
  1  19 250, 0.865950 [0.201210/15.274007] [ 591/0.146969]
  1  19 300, 1.042418 [0.265792/15.275410] [ 641/0.146969]
  1  19 350, 1.250638 [0.234935/15.285498] [ 691/0.146969]
Epoch 19 done. Evaluation:
(47139, 50000)
(7233, 10000)
  2   0  50, 0.104985 [0.112796/15.249939] [   0/0.104985]
  2   0 100, 0.205694 [0.073333/15.210063] [  50/0.104985]
  2   0 150, 0.291781 [0.103591/15.169309] [ 100/0.104985]
  2   0 200, 0.368163 [0.109417/15.126496] [ 150/0.104985]
  2   0 250, 0.446659 [0.109823/15.086212] [ 200/0.104985]
  2   0 300, 0.528007 [0.129067/15.046382] [ 250/0.104985]
  2   0 350, 0.600291 [0.074829/15.006291] [ 300/0.104985]
Epoch 0 done. Evaluation:
(48860, 50000)
(8719, 10000)
  2   1  50, 0.056343 [0.045351/14.933331] [   0/0.056343]
  2   1 100, 0.112799 [0.101811/14.890187] [  50/0.056343]
  2   1 150, 0.171962 [0.053947/14.849966] [ 100/0.056343]
  2   1 200, 0.231093 [0.118393/14.810271] [ 150/0.056343]
  2   1 250, 0.299151 [0.147325/14.772071] [ 200/0.056343]
  2   1 300, 0.362468 [0.100963/14.734883] [ 250/0.056343]
  2   1 350, 0.418582 [0.104360/14.697116] [ 300/0.056343]
Epoch 1 done. Evaluation:
(49245, 50000)
(8693, 10000)
  2   2  50, 0.049305 [0.106582/14.628766] [   0/0.049305]
  2   2 100, 0.107707 [0.044104/14.591506] [  50/0.049305]
  2   2 150, 0.157757 [0.028297/14.550770] [ 100/0.049305]
  2   2 200, 0.219787 [0.094725/14.520303] [ 150/0.049305]
  2   2 250, 0.276535 [0.166953/14.486304] [ 200/0.049305]
  2   2 300, 0.335235 [0.100797/14.454430] [ 250/0.049305]
  2   2 350, 0.406318 [0.130811/14.427000] [ 300/0.049305]
Epoch 2 done. Evaluation:
(49265, 50000)
(8762, 10000)
  2   3  50, 0.043457 [0.091621/14.361922] [   0/0.043457]
  2   3 100, 0.092860 [0.115849/14.328989] [  50/0.043457]
  2   3 150, 0.146457 [0.158072/14.296693] [ 100/0.043457]
  2   3 200, 0.204287 [0.083034/14.266263] [ 150/0.043457]
  2   3 250, 0.254889 [0.143643/14.234262] [ 200/0.043457]
  2   3 300, 0.324516 [0.119450/14.208662] [ 250/0.043457]
  2   3 350, 0.398234 [0.159093/14.186383] [ 300/0.043457]
Epoch 3 done. Evaluation:
(49241, 50000)
(8395, 10000)
  2   4  50, 0.065405 [0.123089/14.142622] [ 391/0.043457]
  2   4 100, 0.126032 [0.153158/14.117136] [ 441/0.043457]
  2   4 150, 0.185306 [0.092194/14.089456] [ 491/0.043457]
  2   4 200, 0.250400 [0.153191/14.064096] [ 541/0.043457]
  2   4 250, 0.318606 [0.119146/14.044208] [ 591/0.043457]
  2   4 300, 0.397916 [0.188506/14.029839] [ 641/0.043457]
  2   4 350, 0.474452 [0.146866/14.014540] [ 691/0.043457]
Epoch 4 done. Evaluation:
(49091, 50000)
(8155, 10000)
  2   5  50, 0.064461 [0.123584/13.977368] [ 782/0.043457]
  2   5 100, 0.132764 [0.075416/13.953639] [ 832/0.043457]
  2   5 150, 0.194218 [0.037665/13.931476] [ 882/0.043457]
  2   5 200, 0.255173 [0.177078/13.908380] [ 932/0.043457]
  2   5 250, 0.323033 [0.191221/13.890831] [ 982/0.043457]
  2   5 300, 0.394473 [0.125985/13.873687] [1032/0.043457]
  2   5 350, 0.467351 [0.153972/13.857193] [1082/0.043457]
Epoch 5 done. Evaluation:
(49092, 50000)
(7897, 10000)
  2   6  50, 0.063680 [0.102116/13.831539] [1173/0.043457]
  2   6 100, 0.140193 [0.153517/13.820408] [1223/0.043457]
  2   6 150, 0.218552 [0.159767/13.807914] [1273/0.043457]
  2   6 200, 0.298854 [0.152802/13.794127] [1323/0.043457]
  2   6 250, 0.374885 [0.175058/13.784845] [1373/0.043457]
  2   6 300, 0.466856 [0.171026/13.780771] [1423/0.043457]
  2   6 350, 0.569575 [0.192450/13.777471] [1473/0.043457]
Epoch 6 done. Evaluation:
(48815, 50000)
(8566, 10000)
  2   7  50, 0.066357 [0.144008/13.756059] [1564/0.043457]
  2   7 100, 0.131064 [0.146493/13.736162] [1614/0.043457]
  2   7 150, 0.213725 [0.147577/13.728938] [1664/0.043457]
  2   7 200, 0.299776 [0.210343/13.719196] [1714/0.043457]
  2   7 250, 0.382081 [0.075983/13.707350] [1764/0.043457]
  2   7 300, 0.471372 [0.196365/13.702795] [1814/0.043457]
  2   7 350, 0.556474 [0.113640/13.695210] [1864/0.043457]
Epoch 7 done. Evaluation:
(48880, 50000)
(8065, 10000)
  2   8  50, 0.077581 [0.230190/13.676734] [1955/0.043457]
  2   8 100, 0.142043 [0.142672/13.656621] [2005/0.043457]
  2   8 150, 0.212179 [0.177604/13.645481] [2055/0.043457]
  2   8 200, 0.305071 [0.217306/13.646021] [2105/0.043457]
  2   8 250, 0.390799 [0.127356/13.636788] [2155/0.043457]
  2   8 300, 0.466471 [0.188988/13.623809] [2205/0.043457]
  2   8 350, 0.563103 [0.210787/13.623077] [2255/0.043457]
Epoch 8 done. Evaluation:
(48876, 50000)
(8365, 10000)
  2   9  50, 0.079081 [0.130162/13.613418] [2346/0.043457]
  2   9 100, 0.168740 [0.102414/13.612885] [2396/0.043457]
  2   9 150, 0.260253 [0.124608/13.609475] [2446/0.043457]
  2   9 200, 0.366577 [0.202785/13.616331] [2496/0.043457]
  2   9 250, 0.464821 [0.151932/13.612970] [2546/0.043457]
  2   9 300, 0.565335 [0.123572/13.608028] [2596/0.043457]
  2   9 350, 0.671223 [0.093596/13.607177] [2646/0.043457]
Epoch 9 done. Evaluation:
(48593, 50000)
(8161, 10000)
  2  10  50, 0.071369 [0.100457/13.590693] [2737/0.043457]
  2  10 100, 0.150950 [0.165798/13.580788] [2787/0.043457]
  2  10 150, 0.237032 [0.125065/13.574283] [2837/0.043457]
  2  10 200, 0.320862 [0.109613/13.568811] [2887/0.043457]
  2  10 250, 0.404379 [0.132312/13.559851] [2937/0.043457]
  2  10 300, 0.508643 [0.137711/13.558407] [2987/0.043457]
  2  10 350, 0.598258 [0.154995/13.554290] [3037/0.043457]
Epoch 10 done. Evaluation:
(48779, 50000)
(8594, 10000)
  2  11  50, 0.066559 [0.153807/13.532014] [3128/0.043457]
  2  11 100, 0.138217 [0.104866/13.522399] [3178/0.043457]
  2  11 150, 0.220726 [0.195578/13.517093] [3228/0.043457]
  2  11 200, 0.306299 [0.178810/13.510228] [3278/0.043457]
  2  11 250, 0.394868 [0.175842/13.509301] [3328/0.043457]
  2  11 300, 0.493252 [0.131933/13.512742] [3378/0.043457]
  2  11 350, 0.599753 [0.090645/13.514426] [3428/0.043457]
Epoch 11 done. Evaluation:
(48751, 50000)
(7911, 10000)
  2  12  50, 0.088617 [0.171462/13.514423] [3519/0.043457]
  2  12 100, 0.159085 [0.121336/13.501019] [3569/0.043457]
  2  12 150, 0.255380 [0.148499/13.506402] [3619/0.043457]
  2  12 200, 0.342117 [0.156095/13.506004] [3669/0.043457]
  2  12 250, 0.437416 [0.170026/13.508146] [3719/0.043457]
  2  12 300, 0.528276 [0.117247/13.508176] [3769/0.043457]
  2  12 350, 0.639694 [0.217152/13.512799] [3819/0.043457]
Epoch 12 done. Evaluation:
(48634, 50000)
(8001, 10000)
  2  13  50, 0.081987 [0.119598/13.508945] [3910/0.043457]
  2  13 100, 0.165770 [0.172427/13.504705] [3960/0.043457]
  2  13 150, 0.248104 [0.070877/13.499946] [4010/0.043457]
  2  13 200, 0.347428 [0.230818/13.504245] [4060/0.043457]
  2  13 250, 0.445657 [0.118347/13.504764] [4110/0.043457]
  2  13 300, 0.548510 [0.245442/13.507302] [4160/0.043457]
  2  13 350, 0.647914 [0.093550/13.510057] [4210/0.043457]
Epoch 13 done. Evaluation:
(48662, 50000)
(8311, 10000)
  2  14  50, 0.071458 [0.110368/13.501071] [4301/0.043457]
  2  14 100, 0.156817 [0.163967/13.496520] [4351/0.043457]
  2  14 150, 0.244137 [0.100503/13.494336] [4401/0.043457]
  2  14 200, 0.326265 [0.156364/13.488817] [4451/0.043457]
  2  14 250, 0.419344 [0.120199/13.491567] [4501/0.043457]
  2  14 300, 0.522641 [0.115889/13.495604] [4551/0.043457]
  2  14 350, 0.631683 [0.194602/13.500204] [4601/0.043457]
Epoch 14 done. Evaluation:
(48674, 50000)
(8140, 10000)
  2  15  50, 0.079919 [0.139391/13.491371] [4692/0.043457]
  2  15 100, 0.156679 [0.069936/13.481288] [4742/0.043457]
  2  15 150, 0.239589 [0.199395/13.476967] [4792/0.043457]
  2  15 200, 0.336096 [0.120031/13.476825] [4842/0.043457]
  2  15 250, 0.430940 [0.160779/13.477043] [4892/0.043457]
  2  15 300, 0.524820 [0.195584/13.483311] [4942/0.043457]
  2  15 350, 0.634110 [0.140042/13.489882] [4992/0.043457]
Epoch 15 done. Evaluation:
(48679, 50000)
(8073, 10000)
  2  16  50, 0.083267 [0.135359/13.482299] [5083/0.043457]
  2  16 100, 0.159239 [0.192291/13.476594] [5133/0.043457]
  2  16 150, 0.257755 [0.169662/13.478572] [5183/0.043457]
  2  16 200, 0.340197 [0.141831/13.474574] [5233/0.043457]
  2  16 250, 0.448927 [0.147503/13.482749] [5283/0.043457]
  2  16 300, 0.560124 [0.161510/13.485227] [5333/0.043457]
  2  16 350, 0.664246 [0.144988/13.486655] [5383/0.043457]
Epoch 16 done. Evaluation:
(48583, 50000)
(8122, 10000)
  2  17  50, 0.092744 [0.205200/13.491459] [5474/0.043457]
  2  17 100, 0.168973 [0.146292/13.481189] [5524/0.043457]
  2  17 150, 0.269419 [0.186038/13.488576] [5574/0.043457]
  2  17 200, 0.375080 [0.155783/13.498114] [5624/0.043457]
  2  17 250, 0.469362 [0.193979/13.498626] [5674/0.043457]
  2  17 300, 0.572772 [0.227107/13.508067] [5724/0.043457]
  2  17 350, 0.676427 [0.169590/13.512218] [5774/0.043457]
Epoch 17 done. Evaluation:
(48586, 50000)
(8032, 10000)
  2  18  50, 0.091866 [0.229557/13.509497] [5865/0.043457]
  2  18 100, 0.175996 [0.164169/13.503181] [5915/0.043457]
  2  18 150, 0.262200 [0.148971/13.496915] [5965/0.043457]
  2  18 200, 0.351676 [0.197390/13.493272] [6015/0.043457]
  2  18 250, 0.442928 [0.174168/13.490926] [6065/0.043457]
  2  18 300, 0.554427 [0.177682/13.498776] [6115/0.043457]
  2  18 350, 0.661706 [0.203867/13.505224] [6165/0.043457]
Epoch 18 done. Evaluation:
(48610, 50000)
(8314, 10000)
  2  19  50, 0.077870 [0.153516/13.501419] [6256/0.043457]
  2  19 100, 0.165999 [0.274676/13.502125] [6306/0.043457]
  2  19 150, 0.259522 [0.090178/13.499480] [6356/0.043457]
  2  19 200, 0.352086 [0.179197/13.496969] [6406/0.043457]
  2  19 250, 0.450406 [0.121977/13.495726] [6456/0.043457]
  2  19 300, 0.544476 [0.144980/13.495686] [6506/0.043457]
  2  19 350, 0.637656 [0.141821/13.495821] [6556/0.043457]
Epoch 19 done. Evaluation:
(48643, 50000)
(8341, 10000)
  3   0  50, 0.061097 [0.030001/13.486269] [6647/0.043457]
  3   0 100, 0.113454 [0.043686/13.468000] [6697/0.043457]
  3   0 150, 0.152725 [0.047697/13.448005] [6747/0.043457]
  3   0 200, 0.193749 [0.081961/13.428216] [6797/0.043457]
  3   0 250, 0.231627 [0.048977/13.407924] [6847/0.043457]
  3   0 300, 0.269540 [0.013949/13.388315] [6897/0.043457]
  3   0 350, 0.307219 [0.045555/13.367945] [6947/0.043457]
Epoch 0 done. Evaluation:
(49542, 50000)
(8823, 10000)
  3   1  50, 0.029822 [0.043625/13.330090] [   0/0.029822]
  3   1 100, 0.061789 [0.099869/13.310626] [  50/0.029822]
  3   1 150, 0.086534 [0.047874/13.289164] [ 100/0.029822]
  3   1 200, 0.111613 [0.022496/13.267566] [ 150/0.029822]
  3   1 250, 0.135986 [0.048242/13.246218] [ 200/0.029822]
  3   1 300, 0.163898 [0.043330/13.224976] [ 250/0.029822]
  3   1 350, 0.188375 [0.022016/13.203866] [ 300/0.029822]
Epoch 1 done. Evaluation:
(49819, 50000)
(8804, 10000)
  3   2  50, 0.023173 [0.005282/13.164325] [   0/0.023173]
  3   2 100, 0.044247 [0.019244/13.142212] [  50/0.023173]
  3   2 150, 0.062717 [0.007053/13.119264] [ 100/0.023173]
  3   2 200, 0.084469 [0.007751/13.097669] [ 150/0.023173]
  3   2 250, 0.105866 [0.004519/13.075784] [ 200/0.023173]
  3   2 300, 0.125463 [0.017628/13.053654] [ 250/0.023173]
  3   2 350, 0.146504 [0.013742/13.031938] [ 300/0.023173]
Epoch 2 done. Evaluation:
(49901, 50000)
(8829, 10000)
  3   3  50, 0.021051 [0.068947/12.992112] [   0/0.021051]
  3   3 100, 0.038934 [0.006388/12.969180] [  50/0.021051]
  3   3 150, 0.054880 [0.052998/12.946154] [ 100/0.021051]
  3   3 200, 0.072994 [0.027369/12.923885] [ 150/0.021051]
  3   3 250, 0.090076 [0.057377/12.901562] [ 200/0.021051]
  3   3 300, 0.108238 [0.055527/12.879742] [ 250/0.021051]
  3   3 350, 0.129881 [0.004020/12.858414] [ 300/0.021051]
Epoch 3 done. Evaluation:
(49930, 50000)
(8864, 10000)
  3   4  50, 0.016250 [0.005801/12.818938] [   0/0.016250]
  3   4 100, 0.032780 [0.003112/12.796527] [  50/0.016250]
  3   4 150, 0.047643 [0.007044/12.773649] [ 100/0.016250]
  3   4 200, 0.063440 [0.007535/12.751363] [ 150/0.016250]
  3   4 250, 0.081000 [0.008266/12.729473] [ 200/0.016250]
  3   4 300, 0.098473 [0.003345/12.707759] [ 250/0.016250]
  3   4 350, 0.114133 [0.010618/12.685526] [ 300/0.016250]
Epoch 4 done. Evaluation:
(49974, 50000)
(8885, 10000)
  3   5  50, 0.014993 [0.002513/12.644859] [   0/0.014993]
  3   5 100, 0.029584 [0.003769/12.622377] [  50/0.014993]
  3   5 150, 0.043333 [0.003222/12.599660] [ 100/0.014993]
  3   5 200, 0.057891 [0.005757/12.577265] [ 150/0.014993]
  3   5 250, 0.073292 [0.011117/12.554846] [ 200/0.014993]
  3   5 300, 0.089798 [0.019689/12.533367] [ 250/0.014993]
  3   5 350, 0.105427 [0.002039/12.511568] [ 300/0.014993]
Epoch 5 done. Evaluation:
(49985, 50000)
(8922, 10000)
  3   6  50, 0.013766 [0.002233/12.471223] [   0/0.013766]
  3   6 100, 0.028121 [0.007409/12.449227] [  50/0.013766]
  3   6 150, 0.042193 [0.014562/12.427170] [ 100/0.013766]
  3   6 200, 0.056024 [0.011156/12.405041] [ 150/0.013766]
  3   6 250, 0.070036 [0.005856/12.383054] [ 200/0.013766]
  3   6 300, 0.084245 [0.012992/12.361236] [ 250/0.013766]
  3   6 350, 0.097999 [0.008098/12.339354] [ 300/0.013766]
Epoch 6 done. Evaluation:
(49997, 50000)
(8928, 10000)
  3   7  50, 0.014135 [0.022632/12.299629] [ 391/0.013766]
  3   7 100, 0.028298 [0.017080/12.278094] [ 441/0.013766]
  3   7 150, 0.041568 [0.007921/12.256222] [ 491/0.013766]
  3   7 200, 0.055397 [0.002093/12.234545] [ 541/0.013766]
  3   7 250, 0.069059 [0.002137/12.212970] [ 591/0.013766]
  3   7 300, 0.083347 [0.003723/12.191734] [ 641/0.013766]
  3   7 350, 0.096773 [0.004252/12.170211] [ 691/0.013766]
Epoch 7 done. Evaluation:
(49997, 50000)
(8933, 10000)
  3   8  50, 0.014287 [0.002822/12.131968] [ 782/0.013766]
  3   8 100, 0.028353 [0.002744/12.110957] [ 832/0.013766]
  3   8 150, 0.041947 [0.003745/12.089771] [ 882/0.013766]
  3   8 200, 0.055281 [0.003106/12.068550] [ 932/0.013766]
  3   8 250, 0.069236 [0.001873/12.047714] [ 982/0.013766]
  3   8 300, 0.083240 [0.002193/12.026916] [1032/0.013766]
  3   8 350, 0.096772 [0.004043/12.006014] [1082/0.013766]
Epoch 8 done. Evaluation:
(49995, 50000)
(8946, 10000)
  3   9  50, 0.013354 [0.003099/11.968221] [   0/0.013354]
  3   9 100, 0.026103 [0.004239/11.947094] [  50/0.013354]
  3   9 150, 0.039963 [0.003097/11.926567] [ 100/0.013354]
  3   9 200, 0.053867 [0.005070/11.906202] [ 150/0.013354]
  3   9 250, 0.067890 [0.002440/11.886074] [ 200/0.013354]
  3   9 300, 0.081591 [0.004942/11.865720] [ 250/0.013354]
  3   9 350, 0.095593 [0.002664/11.845554] [ 300/0.013354]
Epoch 9 done. Evaluation:
(49997, 50000)
(8951, 10000)
  3  10  50, 0.013624 [0.002913/11.808968] [ 391/0.013354]
  3  10 100, 0.027337 [0.002140/11.788839] [ 441/0.013354]
  3  10 150, 0.040771 [0.001810/11.768655] [ 491/0.013354]
  3  10 200, 0.054391 [0.002234/11.748645] [ 541/0.013354]
  3  10 250, 0.067947 [0.001897/11.728661] [ 591/0.013354]
  3  10 300, 0.081237 [0.002192/11.708626] [ 641/0.013354]
  3  10 350, 0.094933 [0.001922/11.688856] [ 691/0.013354]
Epoch 10 done. Evaluation:
(50000, 50000)
(8955, 10000)
  3  11  50, 0.013435 [0.001941/11.652841] [ 782/0.013354]
  3  11 100, 0.027104 [0.001591/11.633224] [ 832/0.013354]
  3  11 150, 0.040549 [0.000995/11.613577] [ 882/0.013354]
  3  11 200, 0.054139 [0.001890/11.594079] [ 932/0.013354]
  3  11 250, 0.067627 [0.005112/11.574549] [ 982/0.013354]
  3  11 300, 0.081063 [0.008858/11.555097] [1032/0.013354]
  3  11 350, 0.094547 [0.003174/11.535747] [1082/0.013354]
Epoch 11 done. Evaluation:
(50000, 50000)
(8962, 10000)
  3  12  50, 0.013103 [0.001730/11.500551] [   0/0.013103]
  3  12 100, 0.026621 [0.001440/11.481396] [  50/0.013103]
  3  12 150, 0.040723 [0.005320/11.462602] [ 100/0.013103]
  3  12 200, 0.054433 [0.001530/11.443663] [ 150/0.013103]
  3  12 250, 0.067916 [0.001974/11.424682] [ 200/0.013103]
  3  12 300, 0.081721 [0.001913/11.405915] [ 250/0.013103]
  3  12 350, 0.095520 [0.004439/11.387203] [ 300/0.013103]
Epoch 12 done. Evaluation:
(50000, 50000)
(8962, 10000)
  3  13  50, 0.014083 [0.002847/11.353329] [ 391/0.013103]
  3  13 100, 0.027722 [0.002085/11.334741] [ 441/0.013103]
  3  13 150, 0.041387 [0.001906/11.316234] [ 491/0.013103]
  3  13 200, 0.055636 [0.006417/11.298042] [ 541/0.013103]
  3  13 250, 0.069262 [0.000994/11.279641] [ 591/0.013103]
  3  13 300, 0.083522 [0.002641/11.261639] [ 641/0.013103]
  3  13 350, 0.097581 [0.002731/11.243562] [ 691/0.013103]
Epoch 13 done. Evaluation:
(50000, 50000)
(8944, 10000)
  3  14  50, 0.013980 [0.001654/11.210734] [ 782/0.013103]
  3  14 100, 0.027377 [0.002496/11.192528] [ 832/0.013103]
  3  14 150, 0.040964 [0.001344/11.174497] [ 882/0.013103]
  3  14 200, 0.054549 [0.001239/11.156489] [ 932/0.013103]
  3  14 250, 0.068271 [0.002195/11.138613] [ 982/0.013103]
  3  14 300, 0.081866 [0.001199/11.120748] [1032/0.013103]
  3  14 350, 0.095744 [0.002157/11.103080] [1082/0.013103]
Epoch 14 done. Evaluation:
(50000, 50000)
(8953, 10000)
  3  15  50, 0.013220 [0.002034/11.070776] [1173/0.013103]
  3  15 100, 0.027039 [0.005117/11.053266] [1223/0.013103]
  3  15 150, 0.040458 [0.001568/11.035615] [1273/0.013103]
  3  15 200, 0.053976 [0.006655/11.018068] [1323/0.013103]
  3  15 250, 0.067945 [0.001820/11.000802] [1373/0.013103]
  3  15 300, 0.081425 [0.001504/10.983383] [1423/0.013103]
  3  15 350, 0.095345 [0.003870/10.966248] [1473/0.013103]
Epoch 15 done. Evaluation:
(49999, 50000)
(8959, 10000)
  3  16  50, 0.014025 [0.002468/10.935470] [1564/0.013103]
  3  16 100, 0.027954 [0.002118/10.918498] [1614/0.013103]
  3  16 150, 0.041425 [0.003104/10.901370] [1664/0.013103]
  3  16 200, 0.054777 [0.001675/10.884226] [1714/0.013103]
  3  16 250, 0.068269 [0.003441/10.867211] [1764/0.013103]
  3  16 300, 0.082042 [0.001530/10.850396] [1814/0.013103]
  3  16 350, 0.095662 [0.002554/10.833560] [1864/0.013103]
Epoch 16 done. Evaluation:
(50000, 50000)
(8961, 10000)
  3  17  50, 0.013960 [0.001350/10.803182] [1955/0.013103]
  3  17 100, 0.027924 [0.003525/10.786712] [2005/0.013103]
  3  17 150, 0.041496 [0.002060/10.770087] [2055/0.013103]
  3  17 200, 0.055128 [0.002571/10.753547] [2105/0.013103]
  3  17 250, 0.068947 [0.001371/10.737168] [2155/0.013103]
  3  17 300, 0.082957 [0.002586/10.720945] [2205/0.013103]
  3  17 350, 0.096984 [0.001816/10.704809] [2255/0.013103]
Epoch 17 done. Evaluation:
(50000, 50000)
(8961, 10000)
  3  18  50, 0.013943 [0.002114/10.675386] [2346/0.013103]
  3  18 100, 0.027914 [0.001631/10.659367] [2396/0.013103]
  3  18 150, 0.041677 [0.001476/10.643299] [2446/0.013103]
  3  18 200, 0.055653 [0.001895/10.627416] [2496/0.013103]
  3  18 250, 0.069917 [0.005164/10.611726] [2546/0.013103]
  3  18 300, 0.083637 [0.001367/10.595817] [2596/0.013103]
  3  18 350, 0.097439 [0.002926/10.580003] [2646/0.013103]
Epoch 18 done. Evaluation:
(50000, 50000)
(8957, 10000)
  3  19  50, 0.013512 [0.001394/10.551490] [2737/0.013103]
  3  19 100, 0.027185 [0.001452/10.535770] [2787/0.013103]
  3  19 150, 0.040874 [0.004359/10.520103] [2837/0.013103]
  3  19 200, 0.054674 [0.004583/10.504571] [2887/0.013103]
  3  19 250, 0.068684 [0.001980/10.489179] [2937/0.013103]
  3  19 300, 0.082915 [0.002326/10.473992] [2987/0.013103]
  3  19 350, 0.096892 [0.002360/10.458717] [3037/0.013103]
Epoch 19 done. Evaluation:
(50000, 50000)
(8953, 10000)
  4   0  50, 0.013665 [0.000623/10.438521] [3128/0.013103]
  4   0 100, 0.027466 [0.001461/10.430892] [3178/0.013103]
  4   0 150, 0.040743 [0.000485/10.423131] [3228/0.013103]
  4   0 200, 0.054258 [0.000559/10.415443] [3278/0.013103]
  4   0 250, 0.068165 [0.001148/10.407884] [3328/0.013103]
  4   0 300, 0.081686 [0.000578/10.400219] [3378/0.013103]
  4   0 350, 0.095703 [0.003752/10.392718] [3428/0.013103]
Epoch 0 done. Evaluation:
(50000, 50000)
(8969, 10000)
  4   1  50, 0.013702 [0.000413/10.379078] [3519/0.013103]
  4   1 100, 0.027653 [0.000692/10.371592] [3569/0.013103]
  4   1 150, 0.041137 [0.000891/10.363992] [3619/0.013103]
  4   1 200, 0.054741 [0.001224/10.356422] [3669/0.013103]
  4   1 250, 0.068073 [0.001386/10.348798] [3719/0.013103]
  4   1 300, 0.082473 [0.001675/10.341480] [3769/0.013103]
  4   1 350, 0.096459 [0.001355/10.334072] [3819/0.013103]
Epoch 1 done. Evaluation:
(50000, 50000)
(8962, 10000)
  4   2  50, 0.013959 [0.000628/10.320588] [3910/0.013103]
  4   2 100, 0.027863 [0.001236/10.313193] [3960/0.013103]
  4   2 150, 0.041735 [0.000791/10.305827] [4010/0.013103]
  4   2 200, 0.055063 [0.001086/10.298297] [4060/0.013103]
  4   2 250, 0.068756 [0.000801/10.290887] [4110/0.013103]
  4   2 300, 0.082616 [0.004043/10.283533] [4160/0.013103]
  4   2 350, 0.096512 [0.000636/10.276206] [4210/0.013103]
Epoch 2 done. Evaluation:
(50000, 50000)
(8958, 10000)
  4   3  50, 0.013954 [0.000601/10.262874] [4301/0.013103]
  4   3 100, 0.027966 [0.000706/10.255622] [4351/0.013103]
  4   3 150, 0.041592 [0.000692/10.248285] [4401/0.013103]
  4   3 200, 0.055547 [0.000661/10.241052] [4451/0.013103]
  4   3 250, 0.069125 [0.001698/10.233725] [4501/0.013103]
  4   3 300, 0.083078 [0.001048/10.226513] [4551/0.013103]
  4   3 350, 0.096974 [0.000552/10.219287] [4601/0.013103]
Epoch 3 done. Evaluation:
(50000, 50000)
(8968, 10000)
  4   4  50, 0.013890 [0.000703/10.206137] [4692/0.013103]
  4   4 100, 0.027513 [0.000746/10.198885] [4742/0.013103]
  4   4 150, 0.041754 [0.001152/10.191814] [4792/0.013103]
  4   4 200, 0.055347 [0.001248/10.184582] [4842/0.013103]
  4   4 250, 0.069755 [0.000779/10.177597] [4892/0.013103]
  4   4 300, 0.083872 [0.001048/10.170518] [4942/0.013103]
  4   4 350, 0.097364 [0.000516/10.163289] [4992/0.013103]
Epoch 4 done. Evaluation:
(50000, 50000)
(8968, 10000)
  4   5  50, 0.013409 [0.000484/10.150205] [5083/0.013103]
  4   5 100, 0.026974 [0.000925/10.143048] [5133/0.013103]
  4   5 150, 0.040610 [0.000737/10.135923] [5183/0.013103]
  4   5 200, 0.054609 [0.000548/10.128897] [5233/0.013103]
  4   5 250, 0.068486 [0.000827/10.121859] [5283/0.013103]
  4   5 300, 0.082553 [0.000578/10.114893] [5333/0.013103]
  4   5 350, 0.096275 [0.000625/10.107836] [5383/0.013103]
Epoch 5 done. Evaluation:
(50000, 50000)
(8961, 10000)
  4   6  50, 0.014192 [0.001446/10.095208] [5474/0.013103]
  4   6 100, 0.028357 [0.001099/10.088308] [5524/0.013103]
  4   6 150, 0.042701 [0.001578/10.081475] [5574/0.013103]
  4   6 200, 0.056476 [0.001545/10.074493] [5624/0.013103]
  4   6 250, 0.070337 [0.000972/10.067548] [5674/0.013103]
  4   6 300, 0.084261 [0.002088/10.060647] [5724/0.013103]
  4   6 350, 0.098136 [0.000827/10.053742] [5774/0.013103]
Epoch 6 done. Evaluation:
(50000, 50000)
(8967, 10000)
  4   7  50, 0.013655 [0.000798/10.041166] [5865/0.013103]
  4   7 100, 0.027552 [0.001529/10.034294] [5915/0.013103]
  4   7 150, 0.041607 [0.001303/10.027485] [5965/0.013103]
  4   7 200, 0.055566 [0.002013/10.020653] [6015/0.013103]
  4   7 250, 0.069216 [0.000520/10.013743] [6065/0.013103]
  4   7 300, 0.083143 [0.000779/10.006950] [6115/0.013103]
  4   7 350, 0.097065 [0.000990/10.000159] [6165/0.013103]
Epoch 7 done. Evaluation:
(50000, 50000)
(8957, 10000)
  4   8  50, 0.013476 [0.000754/9.987804] [6256/0.013103]
  4   8 100, 0.027455 [0.002346/9.981055] [6306/0.013103]
  4   8 150, 0.041054 [0.000556/9.974210] [6356/0.013103]
  4   8 200, 0.054862 [0.000950/9.967436] [6406/0.013103]
  4   8 250, 0.068635 [0.001402/9.960670] [6456/0.013103]
  4   8 300, 0.083201 [0.002036/9.954116] [6506/0.013103]
  4   8 350, 0.097038 [0.000745/9.947392] [6556/0.013103]
Epoch 8 done. Evaluation:
(49999, 50000)
(8959, 10000)
  4   9  50, 0.013644 [0.000778/9.935159] [6647/0.013103]
  4   9 100, 0.027262 [0.001480/9.928422] [6697/0.013103]
  4   9 150, 0.041523 [0.000465/9.921874] [6747/0.013103]
  4   9 200, 0.055429 [0.000556/9.915241] [6797/0.013103]
  4   9 250, 0.069093 [0.001271/9.908546] [6847/0.013103]
  4   9 300, 0.083045 [0.000969/9.901948] [6897/0.013103]
  4   9 350, 0.096755 [0.002387/9.895292] [6947/0.013103]
Epoch 9 done. Evaluation:
(50000, 50000)
(8969, 10000)
  4  10  50, 0.013716 [0.000910/9.883294] [7038/0.013103]
  4  10 100, 0.027279 [0.001222/9.876633] [7088/0.013103]
  4  10 150, 0.040944 [0.001249/9.870001] [7138/0.013103]
  4  10 200, 0.054645 [0.001016/9.863394] [7188/0.013103]
  4  10 250, 0.068563 [0.000864/9.856871] [7238/0.013103]
  4  10 300, 0.082486 [0.000722/9.850367] [7288/0.013103]
  4  10 350, 0.096070 [0.000810/9.843770] [7338/0.013103]
Epoch 10 done. Evaluation:
(50000, 50000)
(8973, 10000)
  4  11  50, 0.013834 [0.000874/9.831889] [7429/0.013103]
  4  11 100, 0.027593 [0.001211/9.825381] [7479/0.013103]
  4  11 150, 0.041348 [0.000610/9.818889] [7529/0.013103]
  4  11 200, 0.055235 [0.001050/9.812443] [7579/0.013103]
  4  11 250, 0.069330 [0.000958/9.806081] [7629/0.013103]
  4  11 300, 0.083135 [0.002698/9.799631] [7679/0.013103]
  4  11 350, 0.097269 [0.000796/9.793305] [7729/0.013103]
Epoch 11 done. Evaluation:
(50000, 50000)
(8971, 10000)
  4  12  50, 0.013828 [0.000573/9.781731] [7820/0.013103]
  4  12 100, 0.027770 [0.000883/9.775374] [7870/0.013103]
  4  12 150, 0.041781 [0.000886/9.769052] [7920/0.013103]
  4  12 200, 0.055794 [0.000874/9.762734] [7970/0.013103]
  4  12 250, 0.069586 [0.000895/9.756374] [8020/0.013103]
  4  12 300, 0.083176 [0.001508/9.749963] [8070/0.013103]
  4  12 350, 0.097353 [0.001564/9.743736] [8120/0.013103]
Epoch 12 done. Evaluation:
(50000, 50000)
(8966, 10000)
  4  13  50, 0.013509 [0.001535/9.732111] [8211/0.013103]
  4  13 100, 0.027633 [0.001459/9.725911] [8261/0.013103]
  4  13 150, 0.041354 [0.001563/9.719600] [8311/0.013103]
  4  13 200, 0.054743 [0.002071/9.713199] [8361/0.013103]
  4  13 250, 0.068523 [0.001555/9.706930] [8411/0.013103]
  4  13 300, 0.082463 [0.000748/9.700717] [8461/0.013103]
  4  13 350, 0.096481 [0.000712/9.694537] [8511/0.013103]
Epoch 13 done. Evaluation:
(50000, 50000)
(8977, 10000)
  4  14  50, 0.013547 [0.000610/9.683160] [8602/0.013103]
  4  14 100, 0.027474 [0.001748/9.676987] [8652/0.013103]
  4  14 150, 0.041128 [0.000532/9.670742] [8702/0.013103]
  4  14 200, 0.054616 [0.001051/9.664462] [8752/0.013103]
  4  14 250, 0.068681 [0.000685/9.658365] [8802/0.013103]
  4  14 300, 0.082457 [0.000861/9.652199] [8852/0.013103]
  4  14 350, 0.096382 [0.000642/9.646098] [8902/0.013103]
Epoch 14 done. Evaluation:
(50000, 50000)
(8969, 10000)
  4  15  50, 0.013558 [0.000684/9.634838] [8993/0.013103]
  4  15 100, 0.027255 [0.000696/9.628699] [9043/0.013103]
  4  15 150, 0.041216 [0.000988/9.622651] [9093/0.013103]
  4  15 200, 0.055067 [0.000701/9.616589] [9143/0.013103]
  4  15 250, 0.068500 [0.001624/9.610391] [9193/0.013103]
  4  15 300, 0.082599 [0.000789/9.604416] [9243/0.013103]
  4  15 350, 0.096285 [0.001257/9.598337] [9293/0.013103]
Epoch 15 done. Evaluation:
(50000, 50000)
(8979, 10000)
  4  16  50, 0.013262 [0.000614/9.587137] [9384/0.013103]
  4  16 100, 0.027101 [0.000819/9.581130] [9434/0.013103]
  4  16 150, 0.040888 [0.000628/9.575110] [9484/0.013103]
  4  16 200, 0.055014 [0.000955/9.569224] [9534/0.013103]
  4  16 250, 0.069124 [0.000845/9.563345] [9584/0.013103]
  4  16 300, 0.082909 [0.001627/9.557373] [9634/0.013103]
  4  16 350, 0.097212 [0.001669/9.551578] [9684/0.013103]
Epoch 16 done. Evaluation:
(50000, 50000)
(8969, 10000)
  4  17  50, 0.013877 [0.000564/9.540707] [9775/0.013103]
  4  17 100, 0.027995 [0.001074/9.534884] [9825/0.013103]
  4  17 150, 0.041641 [0.000763/9.528933] [9875/0.013103]
  4  17 200, 0.055652 [0.001677/9.523106] [9925/0.013103]
  4  17 250, 0.069530 [0.001123/9.517240] [9975/0.013103]
  4  17 300, 0.083561 [0.000979/9.511435] [10025/0.013103]
  4  17 350, 0.097649 [0.000955/9.505652] [10075/0.013103]
Epoch 17 done. Evaluation:
(50000, 50000)
(8980, 10000)
  4  18  50, 0.014066 [0.001145/9.495100] [10166/0.013103]
  4  18 100, 0.027716 [0.000854/9.489227] [10216/0.013103]
  4  18 150, 0.041706 [0.000857/9.483467] [10266/0.013103]
  4  18 200, 0.055614 [0.000616/9.477696] [10316/0.013103]
  4  18 250, 0.069699 [0.000747/9.471981] [10366/0.013103]
  4  18 300, 0.083792 [0.001785/9.466285] [10416/0.013103]
  4  18 350, 0.097483 [0.001827/9.460491] [10466/0.013103]
Epoch 18 done. Evaluation:
(50000, 50000)
(8965, 10000)
  4  19  50, 0.014185 [0.000985/9.450142] [10557/0.013103]
  4  19 100, 0.028055 [0.000506/9.444421] [10607/0.013103]
  4  19 150, 0.041888 [0.001722/9.438709] [10657/0.013103]
  4  19 200, 0.055576 [0.000893/9.432956] [10707/0.013103]
  4  19 250, 0.070058 [0.000662/9.427447] [10757/0.013103]
  4  19 300, 0.084191 [0.001525/9.421858] [10807/0.013103]
  4  19 350, 0.098213 [0.001001/9.416241] [10857/0.013103]
Epoch 19 done. Evaluation:
(50000, 50000)
(8975, 10000)
