Sequential (
  (conv1_1): Sequential (
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (conv1_2): Sequential (
    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (pool1): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
  (conv2_1): Sequential (
    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (conv2_2): Sequential (
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (pool2): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
  (conv3_1): Sequential (
    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (conv3_2): Sequential (
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (pool3): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
  (conv4_1): Sequential (
    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (conv4_2): Sequential (
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (pool4): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
  (conv5_1): Sequential (
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (conv5_2): Sequential (
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (pool5): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
  (fc6): Sequential (
    (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU (inplace)
  )
  (logit): Conv2d(256, 10, kernel_size=(1, 1), stride=(1, 1))
  (flatter): Flatten()
)
{'L1_decay': 5e-06,
 'auto_start': True,
 'batch_size': 128,
 'force_name': False,
 'graphfolder': 'logs/fxp7_graphs/',
 'last2_mult': 1.0,
 'learning_rate': 0.1,
 'logfile': 'logs/fxp7.log',
 'mode': '',
 'momentum': 0.0,
 'name': 'fxp7',
 'num_base': 32,
 'optimizer': 'SGD_var_dup1',
 'weight_decay': 0.00032}
0.00412133582963
0.0454252316847
0.0460784176798
0.0922737057897
0.0923688174853
0.183778364963
0.184365159377
0.369439590689
0.369419606366
0.36844326301
0.0407725222055
0.0409425172309
Decayed training with schedule: [20, 20, 20, 20, 20, 20, 20, 20, 20, 20]
  0   0  50, 1.933861 [0.802507/35.613512] [   0/1.933861]
  0   0 100, 1.822733 [0.279263/26.067341] [   0/1.822733]
  0   0 150, 1.783090 [0.311205/20.911941] [   0/1.783090]
  0   0 200, 1.781311 [0.279908/17.490009] [   0/1.781311]
  0   0 250, 1.790124 [0.328928/15.026526] [  50/1.781311]
  0   0 300, 1.758605 [0.568781/13.266062] [   0/1.758605]
  0   0 350, 1.813187 [0.161866/11.960209] [  50/1.758605]
Showing Monitored Norms
7.023160, 1.682962, 2.040231, 0.783367, 0.787201, 0.462205, 0.431043, 0.311180, 0.303901, 0.394089, 4.672943, 2.156033, 
0.677818, 1.951437, 2.110276, 2.712065, 2.550955, 2.473718, 1.699108, 1.408861, 0.986828, 0.996703, 0.305420, 0.319004, 
-0.000000, 0.000000, -0.000031, -0.000129, -0.000294, 0.008019, -0.015060, -0.064064, -0.029775, -0.061433, -0.004227, -0.043974, 
0.028945, 0.076449, 0.094011, 0.072284, 0.072713, 0.084943, 0.079469, 0.114962, 0.112267, 0.145199, 0.190528, 0.088273, 
0.067844, 0.195293, 0.211237, 0.271303, 0.255198, 0.247545, 0.170026, 0.140832, 0.098982, 0.099833, 0.035773, 0.031905, 
Epoch 0 done. Evaluation:
(15725, 50000)
(1719, 10000)
  0   1  50, 1.778486 [0.363471/10.481844] [ 141/1.758605]
  0   1 100, 1.744240 [0.245457/9.930574] [   0/1.744240]
  0   1 150, 1.743127 [0.329836/9.524858] [   0/1.743127]
  0   1 200, 1.716106 [0.528979/9.238930] [   0/1.716106]
  0   1 250, 1.731578 [0.431491/8.985751] [  50/1.716106]
  0   1 300, 1.711952 [0.224149/8.782585] [   0/1.711952]
  0   1 350, 1.732856 [0.234167/8.590955] [  50/1.711952]
Showing Monitored Norms
6.036404, 1.086917, 0.975235, 0.658781, 0.608128, 0.406971, 0.404474, 0.261634, 0.262049, 0.337456, 1.274058, 2.448178, 
0.405762, 0.799498, 0.698895, 0.666551, 0.597979, 0.626271, 0.662961, 0.565537, 0.557382, 0.534243, 0.204260, 0.271483, 
-0.000000, -0.000004, -0.000591, -0.004726, -0.002557, -0.009856, -0.005288, -0.003111, -0.016423, -0.045248, -0.025372, -0.130476, 
0.024878, 0.049373, 0.044937, 0.060788, 0.056172, 0.074792, 0.074571, 0.096658, 0.096806, 0.124334, 0.051947, 0.100235, 
0.040652, 0.080102, 0.070030, 0.066889, 0.060037, 0.062955, 0.066655, 0.057321, 0.056291, 0.053817, 0.020441, 0.023999, 
Epoch 1 done. Evaluation:
(17650, 50000)
(2365, 10000)
  0   2  50, 1.752103 [0.188572/8.306386] [ 141/1.711952]
  0   2 100, 1.755693 [0.180148/8.195968] [ 191/1.711952]
  0   2 150, 1.705668 [0.539182/8.085999] [   0/1.705668]
  0   2 200, 1.837925 [0.224119/7.909618] [  50/1.705668]
  0   2 250, 1.739338 [0.268954/7.785175] [ 100/1.705668]
  0   2 300, 1.726913 [0.326217/7.720509] [ 150/1.705668]
  0   2 350, 1.702006 [0.272705/7.629790] [   0/1.702006]
Showing Monitored Norms
5.228447, 1.058761, 0.946041, 0.634008, 0.596268, 0.384198, 0.401649, 0.252500, 0.308626, 0.373635, 0.875973, 2.412465, 
0.382053, 0.721353, 0.666976, 0.601143, 0.642866, 0.506601, 0.755426, 0.802551, 0.679547, 0.694976, 0.208961, 0.313548, 
0.000000, -0.000008, -0.000839, -0.000972, -0.002642, -0.003468, -0.001064, -0.008110, 0.001965, -0.018816, -0.038279, -0.135955, 
0.021548, 0.048094, 0.043592, 0.058502, 0.055077, 0.070607, 0.074050, 0.093284, 0.114013, 0.137663, 0.035716, 0.098772, 
0.038266, 0.072295, 0.066834, 0.060389, 0.064500, 0.051102, 0.075894, 0.080702, 0.068937, 0.070481, 0.020544, 0.028498, 
Epoch 2 done. Evaluation:
(17348, 50000)
(1448, 10000)
  0   3  50, 1.846481 [0.243192/7.327725] [  91/1.702006]
  0   3 100, 1.816524 [0.148350/7.166183] [ 141/1.702006]
  0   3 150, 1.880736 [0.135486/6.976187] [ 191/1.702006]
  0   3 200, 1.861878 [0.133969/6.874097] [ 241/1.702006]
  0   3 250, 1.862672 [0.138144/6.770874] [ 291/1.702006]
  0   3 300, 1.843528 [0.143963/6.639176] [ 341/1.702006]
  0   3 350, 1.872040 [0.159432/6.546384] [ 391/1.702006]
Showing Monitored Norms
4.523907, 0.836713, 0.711254, 0.445847, 0.371929, 0.266616, 0.372670, 0.338795, 0.308924, 0.324005, 0.693694, 2.074293, 
0.172139, 0.641049, 0.585994, 0.505210, 0.333343, 0.380423, 0.614886, 0.510718, 0.511825, 0.685777, 0.054501, 0.287171, 
0.000000, -0.000004, 0.000177, -0.000468, 0.003483, 0.001379, -0.002072, -0.000969, -0.002224, -0.008629, -0.016890, -0.086563, 
0.018645, 0.038008, 0.032773, 0.041140, 0.034355, 0.048998, 0.068707, 0.125164, 0.114123, 0.119378, 0.028284, 0.084927, 
0.017315, 0.064217, 0.058692, 0.050684, 0.033547, 0.038374, 0.061848, 0.052560, 0.052391, 0.069461, 0.005306, 0.027382, 
Epoch 3 done. Evaluation:
(12856, 50000)
(2124, 10000)
  0   4  50, 1.944148 [0.112841/6.282372] [ 482/1.702006]
  0   4 100, 1.928876 [0.128468/6.144930] [ 532/1.702006]
  0   4 150, 1.928768 [0.119265/6.032526] [ 582/1.702006]
  0   4 200, 1.919637 [0.198982/5.935209] [ 632/1.702006]
  0   4 250, 1.940254 [0.126288/5.841374] [ 682/1.702006]
  0   4 300, 1.921991 [0.129265/5.750574] [ 732/1.702006]
  0   4 350, 1.928842 [0.144522/5.664003] [ 782/1.702006]
Showing Monitored Norms
3.920859, 0.733158, 0.568698, 0.333848, 0.256595, 0.129848, 0.126727, 0.081786, 0.062442, 0.104583, 0.591967, 1.962368, 
0.595584, 0.934471, 0.609955, 0.584397, 0.293793, 0.364816, 0.275313, 0.122837, 0.063488, 0.092142, 0.020893, 0.156952, 
-0.000001, 0.000000, 0.006053, 0.010425, 0.006613, -0.003960, -0.023724, -0.004457, -0.043834, -0.034175, -0.019736, -0.048673, 
0.016159, 0.033304, 0.026205, 0.030805, 0.023701, 0.023863, 0.023364, 0.030215, 0.023067, 0.038533, 0.024136, 0.080344, 
0.059580, 0.093506, 0.061078, 0.058576, 0.029528, 0.036534, 0.027429, 0.012543, 0.005040, 0.008568, 0.000815, 0.015254, 
Epoch 4 done. Evaluation:
(10167, 50000)
(1663, 10000)
  0   5  50, 1.930144 [0.177762/5.532289] [ 873/1.702006]
  0   5 100, 1.927397 [0.124862/5.486419] [ 923/1.702006]
  0   5 150, 1.936601 [0.105439/5.390728] [ 973/1.702006]
  0   5 200, 1.956111 [0.090898/5.560506] [1023/1.702006]
  0   5 250, 1.959528 [0.162877/5.279018] [1073/1.702006]
  0   5 300, 1.945868 [0.132252/5.174675] [1123/1.702006]
  0   5 350, 1.946339 [0.125389/5.138325] [1173/1.702006]
Showing Monitored Norms
3.448593, 0.767926, 0.573024, 0.294456, 0.233043, 0.155785, 0.137962, 0.107612, 0.131828, 0.117205, 0.573174, 1.901437, 
0.487966, 0.685812, 0.533735, 0.318261, 0.242365, 0.207644, 0.092391, 0.163393, 0.055907, 0.055722, 0.019795, 0.229591, 
0.000002, 0.000025, 0.000109, -0.006777, -0.000734, -0.000816, 0.002716, 0.000042, 0.000035, -0.007173, -0.018620, -0.096459, 
0.014213, 0.034883, 0.026404, 0.027171, 0.021526, 0.028630, 0.025435, 0.039756, 0.048700, 0.043184, 0.023370, 0.077850, 
0.048817, 0.068670, 0.053439, 0.031884, 0.024325, 0.020950, 0.009655, 0.016817, 0.007417, 0.006596, 0.000823, 0.020917, 
Epoch 5 done. Evaluation:
(9621, 50000)
(1425, 10000)
  0   6  50, 1.951031 [0.153073/5.035891] [1264/1.702006]
  0   6 100, 1.933447 [0.139336/4.964588] [1314/1.702006]
  0   6 150, 1.944482 [0.063557/4.905348] [1364/1.702006]
  0   6 200, 1.933221 [0.123090/4.855941] [1414/1.702006]
  0   6 250, 1.943442 [0.112864/4.839317] [1464/1.702006]
  0   6 300, 1.946685 [0.104008/4.779685] [1514/1.702006]
  0   6 350, 1.996189 [0.285653/4.772153] [1564/1.702006]
Showing Monitored Norms
3.071427, 0.796081, 0.617291, 0.270034, 0.220975, 0.121801, 0.164656, 0.130542, 0.103129, 0.100651, 0.541070, 1.796062, 
0.368173, 0.448573, 0.301588, 0.164677, 0.137028, 0.158236, 0.081955, 0.137106, 0.055358, 0.085079, 0.022542, 0.218911, 
-0.000001, -0.000057, -0.000009, 0.000851, 0.002893, 0.001129, 0.001751, 0.000013, 0.001035, -0.015459, -0.021030, -0.093174, 
0.012658, 0.036162, 0.028444, 0.024917, 0.020411, 0.022384, 0.030357, 0.048227, 0.038098, 0.037084, 0.022061, 0.073535, 
0.036839, 0.045002, 0.030293, 0.016668, 0.013897, 0.015997, 0.008800, 0.014535, 0.006778, 0.008641, 0.000818, 0.019906, 
Epoch 6 done. Evaluation:
(9553, 50000)
(1079, 10000)
  0   7  50, 2.070565 [0.094210/4.490817] [1655/1.702006]
  0   7 100, 2.007025 [0.156340/4.505760] [1705/1.702006]
  0   7 150, 2.035774 [0.136743/4.454039] [1755/1.702006]
  0   7 200, 2.042734 [0.085620/4.628527] [1805/1.702006]
  0   7 250, 1.989033 [0.098573/4.355092] [1855/1.702006]
  0   7 300, 1.962209 [0.125697/4.351579] [1905/1.702006]
  0   7 350, 1.969468 [0.096130/4.322212] [1955/1.702006]
Showing Monitored Norms
2.757912, 0.633094, 0.342736, 0.162485, 0.157274, 0.111447, 0.099507, 0.081564, 0.083582, 0.096625, 0.574088, 1.879313, 
0.354526, 0.644060, 0.223085, 0.088523, 0.177282, 0.180565, 0.204424, 0.201359, 0.114620, 0.365891, 0.022413, 0.215101, 
0.000000, -0.000059, -0.001954, 0.007031, 0.011027, 0.001937, 0.016329, 0.011077, 0.050075, 0.006983, -0.022108, -0.098840, 
0.011366, 0.028758, 0.015793, 0.014993, 0.014527, 0.020482, 0.018346, 0.030133, 0.030877, 0.035601, 0.023407, 0.076944, 
0.035471, 0.064470, 0.022350, 0.009095, 0.017877, 0.018194, 0.020670, 0.020523, 0.013109, 0.036829, 0.000391, 0.019230, 
Epoch 7 done. Evaluation:
(9396, 50000)
(961, 10000)
  0   8  50, 1.963130 [0.106886/4.282168] [2046/1.702006]
  0   8 100, 1.960760 [0.086485/4.240952] [2096/1.702006]
  0   8 150, 1.956468 [0.194404/4.225977] [2146/1.702006]
  0   8 200, 2.313045 [0.020744/4.071694] [2196/1.702006]
  0   8 250, 2.303052 [0.013771/3.607173] [2246/1.702006]
  0   8 300, 2.302674 [0.011489/3.306036] [2296/1.702006]
  0   8 350, 2.302837 [0.011512/3.097264] [2346/1.702006]
Showing Monitored Norms
2.410244, 0.232745, 0.125886, 0.019635, 0.028318, 0.002234, 0.002292, 0.000022, 0.000065, 0.000016, 0.197790, 0.694723, 
0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.052994, 
0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, -0.000000, -0.000000, -0.000000, 0.000313, 
0.009933, 0.010573, 0.005801, 0.001812, 0.002616, 0.000411, 0.000423, 0.000008, 0.000024, 0.000006, 0.008064, 0.028444, 
0.000993, 0.001057, 0.000580, 0.000181, 0.000262, 0.000041, 0.000042, 0.000001, 0.000002, 0.000001, 0.000806, 0.006029, 
Epoch 8 done. Evaluation:
(6732, 50000)
(1000, 10000)
  0   9  50, 2.302887 [0.015104/2.845106] [2437/1.702006]
  0   9 100, 2.302861 [0.008251/2.745220] [2487/1.702006]
  0   9 150, 2.302781 [0.009301/2.661517] [2537/1.702006]
  0   9 200, 2.302533 [0.006895/2.589251] [2587/1.702006]
  0   9 250, 2.302925 [0.005669/2.523685] [2637/1.702006]
  0   9 300, 2.302768 [0.006989/2.463865] [2687/1.702006]
  0   9 350, 2.302807 [0.007379/2.408022] [2737/1.702006]
Showing Monitored Norms
2.051458, 0.039243, 0.020688, 0.000523, 0.000752, 0.000002, 0.000002, 0.000000, 0.000000, 0.000000, 0.040035, 0.139398, 
0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.006954, 
0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000176, 
0.008455, 0.001783, 0.000953, 0.000048, 0.000069, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.001632, 0.005707, 
0.000845, 0.000178, 0.000095, 0.000005, 0.000007, 0.000000, 0.000000, 0.000000, 0.000000, 0.000000, 0.000163, 0.000911, 
Epoch 9 done. Evaluation:
(4848, 50000)
(1000, 10000)
  0  10  50, 2.302626 [0.003919/2.313484] [2828/1.702006]
  0  10 100, 2.302871 [0.007815/2.264200] [2878/1.702006]
  0  10 150, 2.302745 [0.009590/2.216924] [2928/1.702006]
  0  10 200, 2.302793 [0.008342/2.170687] [2978/1.702006]
  0  10 250, 2.302837 [0.005807/2.125810] [3028/1.702006]
  0  10 300, 2.302700 [0.009365/2.082334] [3078/1.702006]
  0  10 350, 2.302784 [0.006754/2.039546] [3128/1.702006]
